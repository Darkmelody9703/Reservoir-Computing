{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\snn\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from dgl.nn import EGATConv, EdgeWeightNorm, GraphConv\n",
    "from dgl.utils import expand_as_pair\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Generation Finish\n",
      "finish inference\n",
      "finish inference\n"
     ]
    }
   ],
   "source": [
    "from train_gpu import inference_new\n",
    "run_time = time.strftime(\"%Y.%m.%d-%H-%M-%S\", time.localtime())\n",
    "# param_search(run_time)\n",
    "from config import Config\n",
    "from data import part_DATA\n",
    "from RC import torchRC, EGAT, EGCN\n",
    "import dgl\n",
    "\n",
    "config = Config()\n",
    "config.device = 'cpu'\n",
    "config.data = 'mnist'\n",
    "config.train_num = 1000\n",
    "config.test_num = 1000\n",
    "config.N_in = 28*28\n",
    "config.N_out = 10\n",
    "config.N_hid = 200\n",
    "train_loader, test_loader = part_DATA(config)\n",
    "\n",
    "model = torchRC(config).to(config.device)\n",
    "train_rs, train_label = inference_new(model, config, train_loader,)\n",
    "test_rs, test_label = inference_new(model, config, test_loader,)\n",
    "# Egat = EGAT(config).to(config.device)\n",
    "Egcn = EGCN(config).to(config.device)\n",
    "\n",
    "A = model.reservoir.A.cpu().numpy()\n",
    "edge_index = torch.tensor(np.where(A!=0), dtype=torch.long)\n",
    "edge_attr = torch.tensor(np.array([A[i,j] for i, j in edge_index.T])).to(config.device)\n",
    "u = edge_index[0]\n",
    "v = edge_index[1]\n",
    "g = dgl.graph((u, v)).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.array([0,2,34,56,78])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = train_rs[index][:,1:,0:config.N_hid]\n",
    "# v = v.transpose(1,2).view(-1,30)\n",
    "# node_feat = Egcn(g, v[0:config.N_hid], edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 4, 7, 0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[index].view(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 30, 200])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_v = v.transpose(1,2).reshape(-1, 30)\n",
    "batch_g = dgl.batch([g]*5)\n",
    "batch_edge_attr = torch.cat(([edge_attr]*5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feat = Egcn(batch_g, batch_v, batch_edge_attr)\n",
    "# pred = node_feat.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\44670\\Documents\\GitHub\\Reservoir-Computing\\learn_dgl.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/44670/Documents/GitHub/Reservoir-Computing/learn_dgl.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m batch_label\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_label' is not defined"
     ]
    }
   ],
   "source": [
    "batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 8, 5, 5, 9, 9, 9, 8, 8, 9])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i in conv.named_parameters():\n",
    "    print(i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 30])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\snn\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\graphconv.py:447: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  rst = self._activation(rst)\n"
     ]
    }
   ],
   "source": [
    "u = [0,1,2,3,2,5]\n",
    "v = [1,2,3,4,0,3]\n",
    "g = dgl.graph((u,v))\n",
    "g = dgl.add_self_loop(g)\n",
    "\n",
    "batch_g = dgl.batch([g, g])\n",
    "feat = torch.ones(6, 3)\n",
    "batch_f = torch.cat([feat, feat])\n",
    "\n",
    "edge_weight = torch.tensor([0.5, 0.6, 0.4, 0.7, 0.9, 0.1, 1, 1, 1, 1, 1, 1])\n",
    "norm = EdgeWeightNorm(norm='both')\n",
    "norm_edge_weight = norm(g, edge_weight)\n",
    "conv1 = GraphConv(3, 2, norm='none', weight=True, bias=True, activation=None)\n",
    "conv2 = GraphConv(3, 2, norm='none', weight=True, bias=True, activation=nn.Softmax())\n",
    "conv2.weight = conv1.weight\n",
    "conv2.bias = conv1.bias\n",
    "\n",
    "# out1 = conv(batch_g, batch_f, edge_weight=norm_edge_weight)\n",
    "out2 = conv1(batch_g, batch_f, edge_weight=None)\n",
    "out3 = conv2(batch_g, batch_f, edge_weight=None)\n",
    "# out3 = conv(g, feat, edge_weight=edge_weight)\n",
    "# print(out1,'\\n', out2, '\\n', out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-3.1475,  0.8163],\n",
       "         [-3.1475,  0.8163],\n",
       "         [-3.1475,  0.8163],\n",
       "         [-4.7213,  1.2245],\n",
       "         [-3.1475,  0.8163],\n",
       "         [-1.5738,  0.4082],\n",
       "         [-3.1475,  0.8163],\n",
       "         [-3.1475,  0.8163],\n",
       "         [-3.1475,  0.8163],\n",
       "         [-4.7213,  1.2245],\n",
       "         [-3.1475,  0.8163],\n",
       "         [-1.5738,  0.4082]], grad_fn=<AddBackward0>),\n",
       " tensor([[0.0186, 0.9814],\n",
       "         [0.0186, 0.9814],\n",
       "         [0.0186, 0.9814],\n",
       "         [0.0026, 0.9974],\n",
       "         [0.0186, 0.9814],\n",
       "         [0.1211, 0.8789],\n",
       "         [0.0186, 0.9814],\n",
       "         [0.0186, 0.9814],\n",
       "         [0.0186, 0.9814],\n",
       "         [0.0026, 0.9974],\n",
       "         [0.0186, 0.9814],\n",
       "         [0.1211, 0.8789]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2,out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert Sparse layout tensor to numpy.convert the tensor to a strided layout first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\GitHubClone\\Reservoir-Computing\\learn_dgl.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/GitHubClone/Reservoir-Computing/learn_dgl.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39madjacency_matrix()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/GitHubClone/Reservoir-Computing/learn_dgl.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m a\u001b[39m.\u001b[39;49mnumpy()\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert Sparse layout tensor to numpy.convert the tensor to a strided layout first."
     ]
    }
   ],
   "source": [
    "a = graph.adjacency_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 3, 15]), torch.Size([30, 3, 1]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes, num_edges = 8, 30\n",
    "node_dim = 20\n",
    "edge_dim = 1\n",
    "graph = dgl.rand_graph(num_nodes, num_edges)\n",
    "node_feats = torch.rand((num_nodes, node_dim))\n",
    "edge_feats = torch.rand((num_edges, edge_dim))\n",
    "egat = EGATConv(in_node_feats=node_dim,\n",
    "                in_edge_feats=edge_dim,\n",
    "                out_node_feats=15,\n",
    "                out_edge_feats=1,\n",
    "                num_heads=3)\n",
    "#forward pass\n",
    "new_node_feats, new_edge_feats = egat(graph, node_feats, edge_feats)\n",
    "new_node_feats.shape, new_edge_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7398],\n",
       "        [2.1219],\n",
       "        [0.2601]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_edge_feats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3739], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_edge_feats.mean(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Number of categories: 7\n",
      "{'train_mask': tensor([ True,  True,  True,  ..., False, False, False]), 'label': tensor([3, 4, 4,  ..., 3, 3, 3]), 'val_mask': tensor([False, False, False,  ..., False, False, False]), 'test_mask': tensor([False, False, False,  ...,  True,  True,  True]), 'feat': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n"
     ]
    }
   ],
   "source": [
    "import dgl.data\n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset('./data')\n",
    "print('Number of categories:', dataset.num_classes)\n",
    "g = dataset[0]\n",
    "print(g.ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "# Create the model with given dimensions\n",
    "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GCN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\44670\\Documents\\GitHub\\Reservoir-Computing\\learn_dgl.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/44670/Documents/GitHub/Reservoir-Computing/learn_dgl.ipynb#W4sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         \u001b[39mif\u001b[39;00m e \u001b[39m%\u001b[39m \u001b[39m5\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/44670/Documents/GitHub/Reservoir-Computing/learn_dgl.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mIn epoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, loss: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m, val acc: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m (best \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m), test acc: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m (best \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/44670/Documents/GitHub/Reservoir-Computing/learn_dgl.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m                 e, loss, val_acc, best_val_acc, test_acc, best_test_acc))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/44670/Documents/GitHub/Reservoir-Computing/learn_dgl.ipynb#W4sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m model \u001b[39m=\u001b[39m GCN(g\u001b[39m.\u001b[39mndata[\u001b[39m'\u001b[39m\u001b[39mfeat\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39m16\u001b[39m, dataset\u001b[39m.\u001b[39mnum_classes)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/44670/Documents/GitHub/Reservoir-Computing/learn_dgl.ipynb#W4sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m train(g, model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GCN' is not defined"
     ]
    }
   ],
   "source": [
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    for e in range(30):\n",
    "        logits = model(g, features)\n",
    "        pred = logits.argmax(1)\n",
    "        # Compute loss\n",
    "        # Note that you should only compute the losses of the nodes in the training set.\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "\n",
    "        # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n",
    "                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))\n",
    "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
    "train(g, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 101, 200])\n"
     ]
    }
   ],
   "source": [
    "from config import Config as config\n",
    "from RC import torchRC\n",
    "model = torchRC(config)\n",
    "mem, spike = model(torch.rand(16, config.frames, 50))\n",
    "print(mem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = model.reservoir.A.numpy()\n",
    "edge_index = torch.tensor(np.where(A!=0), dtype=torch.long)\n",
    "edge_attr = torch.tensor(np.array([A[i,j] for i,j in edge_index.T]))\n",
    "u = edge_index[0]\n",
    "v = edge_index[1]\n",
    "mems = mem[0,0,1:].T\n",
    "g = dgl.graph((u, v))\n",
    "g.ndata['x'] = mems\n",
    "g.edata['w'] = edge_attr\n",
    "\n",
    "h = dgl.graph((u, v))\n",
    "h.ndata['x'] = mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.graph((u, v))\n",
    "g.ndata['x'] = mems\n",
    "g.edata['w'] = edge_attr\n",
    "\n",
    "h = dgl.graph((u, v))\n",
    "h.ndata['x'] = mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "conv1 = GraphConv(config.frames, 16)\n",
    "out = conv1(g, mems)\n",
    "out_h = conv1(h, mems)\n",
    "print(out_h[0])\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3371, -0.0486,  0.0422,  ...,  0.0489, -0.0459,  0.3718])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "conv2 = GCNConv(100, 16)\n",
    "conv2(mems, edge_index, edge_attr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96ca7db0d1355d3f1d1292f46c309caf11ab6e8ea058097f61d052e5011e4d25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
