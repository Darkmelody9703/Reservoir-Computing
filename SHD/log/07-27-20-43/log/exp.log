===== Exp configuration =====
neuron_type:		RadLIF
nb_inputs:		700
nb_outputs:		20
nb_layers:		3
nb_hiddens:		1024
nb_steps:		100
pdrop:		0.1
normalization:		batchnorm
use_bias:		False
bidirectional:		False
date:		07-27-20-43
use_pretrained_model:		False
only_do_testing:		False
load_exp_folder:		None
new_exp_folder:		./log/07-27-20-43/
dataset_name:		shd
data_folder:		data/raw/
save_best:		True
batch_size:		128
nb_epochs:		50
dropout:		0.75
dropout_stop:		0.95
dropout_stepping:		0.02
ckpt_freq:		5
start_epoch:		0
lr:		0.01
scheduler_patience:		2
scheduler_factor:		0.7
use_regularizers:		False
reg_factor:		0.5
reg_fmin:		0.01
reg_fmax:		0.1
use_augm:		False
use_readout_layer:		True
threshold:		1.0
device:		cuda

Device is set to cuda

Number of examples in train set: 8156
SHD does not have a validation split. Using test split.
Number of examples in test set: 2264

Created new spiking model:
 SNN(
  (snn): ModuleList(
    (0): RadLIFLayer(
      (W): Linear(in_features=700, out_features=1024, bias=False)
      (V): Linear(in_features=1024, out_features=1024, bias=False)
      (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (1): RadLIFLayer(
      (W): Linear(in_features=1024, out_features=1024, bias=False)
      (V): Linear(in_features=1024, out_features=1024, bias=False)
      (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (2): ReadoutLayer(
      (W): Linear(in_features=1024, out_features=20, bias=False)
      (norm): BatchNorm1d(20, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
  )
)

Total number of trainable parameters is 3895356

------ Begin training ------

Epoch 1: train loss=1.9095854349434376, acc=0.4272407863451087, fr=0.0758146345615387, lr=0.01, time=0:00:35.581982, cin=0.006790464743971825, cout=0.0343344509601593
Epoch 1: valid loss=0.9778614242871603, acc=0.68521148989899, fr=0.08237776905298233, mask=0.875, time=0:00:06.176214

Best model saved with valid acc=0.68521148989899

-----------------------------

Epoch 2: train loss=0.5159972256515175, acc=0.828475288722826, fr=0.08361736685037613, lr=0.01, time=0:00:32.085874, cin=0.006959554739296436, cout=0.04137451574206352
Epoch 2: valid loss=0.6675946596595976, acc=0.7989662247474747, fr=0.08922944217920303, mask=0.8784456253051758, time=0:00:05.726111

Best model saved with valid acc=0.7989662247474747

-----------------------------

Epoch 3: train loss=0.2516111717559397, acc=0.9190992272418479, fr=0.08262614160776138, lr=0.01, time=0:00:30.803540, cin=0.007001738995313644, cout=0.053377583622932434
Epoch 3: valid loss=0.5186534308724933, acc=0.84375, fr=0.0882422998547554, mask=0.8808045387268066, time=0:00:05.820569

Best model saved with valid acc=0.84375

-----------------------------

Epoch 4: train loss=0.20294562866911292, acc=0.9370913298233696, fr=0.08144629001617432, lr=0.01, time=0:00:30.985919, cin=0.0075209857895970345, cout=0.052729710936546326
Epoch 4: valid loss=0.40835412757264244, acc=0.8649779040404041, fr=0.0847272053360939, mask=0.8831963539123535, time=0:00:05.643648

Best model saved with valid acc=0.8649779040404041

-----------------------------

Epoch 5: train loss=0.12682846991810948, acc=0.9616964588994565, fr=0.0813005119562149, lr=0.01, time=0:00:31.099022, cin=0.007513337768614292, cout=0.054775021970272064
Epoch 5: valid loss=0.41374175084961784, acc=0.8748027146464646, fr=0.08627688139677048, mask=0.8855295181274414, time=0:00:05.952744

Best model saved with valid acc=0.8748027146464646

-----------------------------

Epoch 6: train loss=0.08345257904147729, acc=0.974609375, fr=0.08183286339044571, lr=0.01, time=0:00:31.315921, cin=0.009008664637804031, cout=0.056774139404296875
Epoch 6: valid loss=0.328757353954845, acc=0.9005287247474748, fr=0.0881367176771164, mask=0.8878798484802246, time=0:00:05.780313

Best model saved with valid acc=0.9005287247474748

-----------------------------

Epoch 7: train loss=0.08152899230481125, acc=0.9729269276494565, fr=0.08197420835494995, lr=0.01, time=0:00:30.957287, cin=0.006451737135648727, cout=0.0594630129635334
Epoch 7: valid loss=0.3915117217434777, acc=0.8838778409090909, fr=0.08515920490026474, mask=0.8901209831237793, time=0:00:05.845943

-----------------------------

Epoch 8: train loss=0.07907412521308288, acc=0.9754426375679348, fr=0.08092900365591049, lr=0.01, time=0:00:31.384467, cin=0.006738429423421621, cout=0.06139027327299118
Epoch 8: valid loss=0.437443357374933, acc=0.8780776515151515, fr=0.08654660731554031, mask=0.8923568725585938, time=0:00:05.895049

-----------------------------

Epoch 9: train loss=0.056720601685810834, acc=0.9837646484375, fr=0.08185242116451263, lr=0.01, time=0:00:32.291341, cin=0.00667816586792469, cout=0.043493129312992096
Epoch 9: valid loss=0.45527183678415084, acc=0.890625, fr=0.0850362777709961, mask=0.8945527076721191, time=0:00:05.807029

-----------------------------

Epoch 10: train loss=0.030941122939111665, acc=0.9904307489809783, fr=0.080365851521492, lr=0.006999999999999999, time=0:00:31.328543, cin=0.005351967178285122, cout=0.04434044659137726
Epoch 10: valid loss=0.2603476449019379, acc=0.9250710227272728, fr=0.08464986085891724, mask=0.896690845489502, time=0:00:06.013186

Best model saved with valid acc=0.9250710227272728

-----------------------------

Epoch 11: train loss=0.02042299063396058, acc=0.9944590692934783, fr=0.07904484868049622, lr=0.006999999999999999, time=0:00:33.710102, cin=0.005705736577510834, cout=0.051596879959106445
Epoch 11: valid loss=0.8180103119876649, acc=0.8527067550505051, fr=0.08340449631214142, mask=0.8987693786621094, time=0:00:06.185121

-----------------------------

Epoch 12: train loss=0.020373902545543388, acc=0.9937744140625, fr=0.07899542152881622, lr=0.006999999999999999, time=0:00:32.505840, cin=0.006335700396448374, cout=0.05107148736715317
Epoch 12: valid loss=0.3386361516184277, acc=0.915719696969697, fr=0.08332882821559906, mask=0.900792121887207, time=0:00:05.820320

-----------------------------

Epoch 13: train loss=0.019349263038748177, acc=0.9947032099184783, fr=0.07909612357616425, lr=0.006999999999999999, time=0:00:31.390621, cin=0.004982799757272005, cout=0.04469989985227585
Epoch 13: valid loss=0.39538489613268113, acc=0.9088147095959597, fr=0.08426079899072647, mask=0.9027895927429199, time=0:00:05.874909

-----------------------------

Epoch 14: train loss=0.02347435406591103, acc=0.993408203125, fr=0.07947275787591934, lr=0.004899999999999999, time=0:00:31.429829, cin=0.00472411559894681, cout=0.04667583853006363
Epoch 14: valid loss=0.37665043647090596, acc=0.9116556186868687, fr=0.08431102335453033, mask=0.9047446250915527, time=0:00:06.014445

-----------------------------

Epoch 15: train loss=0.009680825318355346, acc=0.997802734375, fr=0.0791688933968544, lr=0.004899999999999999, time=0:00:31.647966, cin=0.004835383966565132, cout=0.052159857004880905
Epoch 15: valid loss=0.24027128020922342, acc=0.9298453282828283, fr=0.0838766023516655, mask=0.9066343307495117, time=0:00:06.005296

Best model saved with valid acc=0.9298453282828283

-----------------------------

Epoch 16: train loss=0.009784722682525171, acc=0.9979248046875, fr=0.07906243205070496, lr=0.004899999999999999, time=0:00:31.716288, cin=0.005152574740350246, cout=0.05386985093355179
Epoch 16: valid loss=0.3620410967204306, acc=0.915719696969697, fr=0.08346635848283768, mask=0.9084901809692383, time=0:00:05.932867

-----------------------------

Epoch 17: train loss=0.009170559029371361, acc=0.998291015625, fr=0.07938048988580704, lr=0.004899999999999999, time=0:00:31.529984, cin=0.006232311483472586, cout=0.05317283794283867
Epoch 17: valid loss=0.2571900346212917, acc=0.9313841540404041, fr=0.08431801199913025, mask=0.9103631973266602, time=0:00:05.865798

Best model saved with valid acc=0.9313841540404041

-----------------------------

Epoch 18: train loss=0.01145922298746882, acc=0.9973887567934783, fr=0.07910051941871643, lr=0.004899999999999999, time=0:00:32.988440, cin=0.0055412594228982925, cout=0.05345974862575531
Epoch 18: valid loss=0.3876687213778496, acc=0.9094460227272728, fr=0.08381927013397217, mask=0.9121713638305664, time=0:00:06.374434

-----------------------------

Epoch 19: train loss=0.0077811357423343, acc=0.9979248046875, fr=0.07897798717021942, lr=0.004899999999999999, time=0:00:33.787376, cin=0.005892039742320776, cout=0.05150428041815758
Epoch 19: valid loss=0.43045098665687775, acc=0.9009627525252526, fr=0.08393960446119308, mask=0.9138984680175781, time=0:00:06.020712

-----------------------------

Epoch 20: train loss=0.007884164377173875, acc=0.9971711531929348, fr=0.07901245355606079, lr=0.004899999999999999, time=0:00:31.502149, cin=0.005842464044690132, cout=0.04899127036333084
Epoch 20: valid loss=0.48037368390295243, acc=0.9046322601010102, fr=0.08320312201976776, mask=0.9156107902526855, time=0:00:06.436891

-----------------------------

Epoch 21: train loss=0.004970897408838937, acc=0.9989013671875, fr=0.0781020075082779, lr=0.003429999999999999, time=0:00:31.924409, cin=0.005936792120337486, cout=0.04876940697431564
Epoch 21: valid loss=0.41881374849213493, acc=0.9163904671717172, fr=0.0829431414604187, mask=0.9173293113708496, time=0:00:06.002428

-----------------------------

Epoch 22: train loss=0.004052901605518855, acc=0.9991455078125, fr=0.07784388959407806, lr=0.003429999999999999, time=0:00:31.316389, cin=0.0056150080636143684, cout=0.04534876346588135
Epoch 22: valid loss=0.3297056742012501, acc=0.9194286616161617, fr=0.08271943032741547, mask=0.919013500213623, time=0:00:06.023821

-----------------------------

Epoch 23: train loss=0.003871634556844583, acc=0.999267578125, fr=0.07782145589590073, lr=0.003429999999999999, time=0:00:31.590967, cin=0.005690103396773338, cout=0.04381852596998215
Epoch 23: valid loss=0.4108167158232795, acc=0.9009627525252526, fr=0.08226951956748962, mask=0.9206657409667969, time=0:00:06.066560

-----------------------------

Epoch 24: train loss=0.0040660564936843, acc=0.999267578125, fr=0.07742519676685333, lr=0.002400999999999999, time=0:00:31.442427, cin=0.005759855266660452, cout=0.042716868221759796
Epoch 24: valid loss=0.5100876929031478, acc=0.8914141414141414, fr=0.08218774199485779, mask=0.9222569465637207, time=0:00:05.878413

-----------------------------

Epoch 25: train loss=0.003481996523532871, acc=0.99951171875, fr=0.07722385227680206, lr=0.002400999999999999, time=0:00:31.480923, cin=0.00570613332092762, cout=0.03995262086391449
Epoch 25: valid loss=0.4236635946565204, acc=0.9031723484848485, fr=0.08166788518428802, mask=0.9238219261169434, time=0:00:06.068749

-----------------------------

Epoch 26: train loss=0.002314825955181732, acc=0.999755859375, fr=0.07680166512727737, lr=0.002400999999999999, time=0:00:31.732926, cin=0.006091367918998003, cout=0.036747463047504425
Epoch 26: valid loss=0.3826093657149209, acc=0.9148516414141414, fr=0.08153171092271805, mask=0.925349235534668, time=0:00:06.091564

-----------------------------

Epoch 27: train loss=0.0020614206437130633, acc=0.999755859375, fr=0.07646834850311279, lr=0.0016806999999999992, time=0:00:31.505206, cin=0.006415731273591518, cout=0.03460986539721489
Epoch 27: valid loss=0.37366899268494713, acc=0.9153251262626263, fr=0.08128117024898529, mask=0.9268174171447754, time=0:00:05.979865

-----------------------------

Epoch 28: train loss=0.0023199880129141093, acc=0.999755859375, fr=0.07615360617637634, lr=0.0016806999999999992, time=0:00:31.472192, cin=0.006261868868023157, cout=0.03677452355623245
Epoch 28: valid loss=0.36782896104786134, acc=0.9135495580808082, fr=0.08087876439094543, mask=0.9282922744750977, time=0:00:06.034554

-----------------------------

Epoch 29: train loss=0.0018756429865334212, acc=0.999755859375, fr=0.0758814886212349, lr=0.0016806999999999992, time=0:00:31.515745, cin=0.006134443450719118, cout=0.03482845425605774
Epoch 29: valid loss=0.3538922145962715, acc=0.9155224116161617, fr=0.08063933998346329, mask=0.9297113418579102, time=0:00:06.100684

-----------------------------

Epoch 30: train loss=0.002014214024256944, acc=0.9996337890625, fr=0.07560653984546661, lr=0.0011764899999999994, time=0:00:31.294134, cin=0.00612565828487277, cout=0.033039990812540054
Epoch 30: valid loss=0.35814350015587276, acc=0.9202572601010102, fr=0.08032446354627609, mask=0.9311800003051758, time=0:00:05.894818

-----------------------------

Epoch 31: train loss=0.0017470005332143046, acc=0.9998779296875, fr=0.07532360404729843, lr=0.0011764899999999994, time=0:00:31.424522, cin=0.006327287759631872, cout=0.03247726708650589
Epoch 31: valid loss=0.3797266015575992, acc=0.9150883838383839, fr=0.08004093915224075, mask=0.932581901550293, time=0:00:06.203400

-----------------------------

Epoch 32: train loss=0.0018622948268784967, acc=0.9998779296875, fr=0.07515495270490646, lr=0.0011764899999999994, time=0:00:31.305619, cin=0.006965688429772854, cout=0.03133605048060417
Epoch 32: valid loss=0.3503771639532513, acc=0.9157591540404041, fr=0.07984557002782822, mask=0.9339466094970703, time=0:00:06.024685

-----------------------------

Epoch 33: train loss=0.0015023386731627397, acc=0.999755859375, fr=0.07497569918632507, lr=0.0008235429999999996, time=0:00:31.557241, cin=0.00712403142824769, cout=0.02998773194849491
Epoch 33: valid loss=0.3678273881475131, acc=0.9133522727272728, fr=0.07977639883756638, mask=0.9352860450744629, time=0:00:06.017879

-----------------------------

Epoch 34: train loss=0.00194159086640866, acc=0.9996337890625, fr=0.07469300180673599, lr=0.0008235429999999996, time=0:00:31.432108, cin=0.0071265180595219135, cout=0.03019643761217594
Epoch 34: valid loss=0.39030759947167504, acc=0.9150883838383839, fr=0.07942619174718857, mask=0.936591625213623, time=0:00:05.950583

-----------------------------

Epoch 35: train loss=0.002117958558301325, acc=0.99951171875, fr=0.07441399246454239, lr=0.0008235429999999996, time=0:00:31.527445, cin=0.0068497550673782825, cout=0.030481893569231033
Epoch 35: valid loss=0.38957679437266457, acc=0.9114188762626263, fr=0.07916034013032913, mask=0.9378962516784668, time=0:00:06.042621

-----------------------------

Epoch 36: train loss=0.002017766539211152, acc=0.9997080927309783, fr=0.07419265806674957, lr=0.0005764800999999997, time=0:00:31.817413, cin=0.006389607675373554, cout=0.030821390450000763
Epoch 36: valid loss=0.3633822529680199, acc=0.9127209595959597, fr=0.07902157306671143, mask=0.9391388893127441, time=0:00:06.083550

-----------------------------

Epoch 37: train loss=0.001753602791495723, acc=0.9998779296875, fr=0.07400047034025192, lr=0.0005764800999999997, time=0:00:31.816154, cin=0.006511756684631109, cout=0.02964741550385952
Epoch 37: valid loss=0.3997102951010068, acc=0.9079466540404041, fr=0.07867879420518875, mask=0.9403872489929199, time=0:00:05.934325

-----------------------------

Epoch 38: train loss=0.0021937018086646276, acc=0.999755859375, fr=0.0737743228673935, lr=0.0005764800999999997, time=0:00:31.434446, cin=0.006103082560002804, cout=0.02733009308576584
Epoch 38: valid loss=0.36963331864939797, acc=0.9181265782828283, fr=0.07854773104190826, mask=0.9416022300720215, time=0:00:05.964577

-----------------------------

Epoch 39: train loss=0.0020527313818092807, acc=0.9996337890625, fr=0.07360140234231949, lr=0.00040353606999999974, time=0:00:31.506456, cin=0.005944502539932728, cout=0.028291817754507065
Epoch 39: valid loss=0.34662576764822006, acc=0.9170217803030304, fr=0.07839735597372055, mask=0.9427590370178223, time=0:00:06.047336

-----------------------------

Epoch 40: train loss=0.002205627227340301, acc=0.999755859375, fr=0.07340162247419357, lr=0.00040353606999999974, time=0:00:31.764421, cin=0.0059827337972819805, cout=0.03058345429599285
Epoch 40: valid loss=0.35965942674212986, acc=0.9159564393939394, fr=0.07817666977643967, mask=0.9438977241516113, time=0:00:06.048067

-----------------------------

Epoch 41: train loss=0.0015243565051150654, acc=1.0, fr=0.07308067381381989, lr=0.00040353606999999974, time=0:00:31.662210, cin=0.005863640923053026, cout=0.03185295686125755
Epoch 41: valid loss=0.3505239188671112, acc=0.9181265782828283, fr=0.07780905067920685, mask=0.9450335502624512, time=0:00:06.011778

-----------------------------

Epoch 42: train loss=0.0019702729327946145, acc=0.9998779296875, fr=0.07287420332431793, lr=0.0002824752489999998, time=0:00:31.494718, cin=0.005715558771044016, cout=0.031107941642403603
Epoch 42: valid loss=0.34843851667311454, acc=0.9183238636363638, fr=0.07762279361486435, mask=0.9461503028869629, time=0:00:05.916422

-----------------------------

Epoch 43: train loss=0.0018682240217913204, acc=0.9998779296875, fr=0.07260971516370773, lr=0.0002824752489999998, time=0:00:31.663803, cin=0.005781333893537521, cout=0.03013763576745987
Epoch 43: valid loss=0.3490981501009729, acc=0.9172585227272728, fr=0.07733666896820068, mask=0.9472341537475586, time=0:00:05.995277

-----------------------------

Epoch 44: train loss=0.002244722723844461, acc=0.999755859375, fr=0.07239245623350143, lr=0.0002824752489999998, time=0:00:31.743337, cin=0.0055563063360750675, cout=0.0280754454433918
Epoch 44: valid loss=0.3781547107630306, acc=0.9098800505050506, fr=0.07707030326128006, mask=0.9482975006103516, time=0:00:06.058539

-----------------------------

Epoch 45: train loss=0.002209012919365705, acc=0.999755859375, fr=0.07216503471136093, lr=0.00019773267429999984, time=0:00:31.829288, cin=0.005336045287549496, cout=0.028527308255434036
Epoch 45: valid loss=0.36787533428933883, acc=0.9148516414141414, fr=0.07693426311016083, mask=0.9493565559387207, time=0:00:05.998087

-----------------------------

Epoch 46: train loss=0.0014660619822279841, acc=1.0, fr=0.07204171270132065, lr=0.00019773267429999984, time=0:00:31.647253, cin=0.005425631068646908, cout=0.025690339505672455
Epoch 46: valid loss=0.3636235934164789, acc=0.9131549873737375, fr=0.07670476287603378, mask=0.9503707885742188, time=0:00:05.931583

-----------------------------

Epoch 47: train loss=0.001777207827217353, acc=0.9998779296875, fr=0.07201779633760452, lr=0.00019773267429999984, time=0:00:32.366343, cin=0.0054289973340928555, cout=0.02561982534825802
Epoch 47: valid loss=0.3647499241762691, acc=0.9161537247474748, fr=0.07681769877672195, mask=0.9503707885742188, time=0:00:06.151897

-----------------------------

Epoch 48: train loss=0.00204344701228365, acc=0.9998779296875, fr=0.07208052277565002, lr=0.00013841287200999988, time=0:00:31.646255, cin=0.00543846283107996, cout=0.025596074759960175
Epoch 48: valid loss=0.36429791897535324, acc=0.9159564393939394, fr=0.07682536542415619, mask=0.9503707885742188, time=0:00:06.187205

-----------------------------

Epoch 49: train loss=0.0016351730978385604, acc=0.9998779296875, fr=0.07206209748983383, lr=0.00013841287200999988, time=0:00:31.599058, cin=0.0054368735291063786, cout=0.02559591643512249
Epoch 49: valid loss=0.350043842362033, acc=0.9166272095959597, fr=0.07679612934589386, mask=0.9503707885742188, time=0:00:06.051029

-----------------------------

Epoch 50: train loss=0.0015700852759437112, acc=0.9998779296875, fr=0.0720781460404396, lr=0.00013841287200999988, time=0:00:31.537099, cin=0.0054407850839197636, cout=0.02558201365172863
Epoch 50: valid loss=0.3643412051929368, acc=0.9174558080808082, fr=0.07675367593765259, mask=0.9503707885742188, time=0:00:06.045430

-----------------------------


Best valid acc at epoch 17: 0.9313841540404041


------ Training finished ------

