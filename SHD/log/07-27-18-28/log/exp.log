===== Exp configuration =====
neuron_type:		RadLIF
nb_inputs:		700
nb_outputs:		20
nb_layers:		3
nb_hiddens:		1024
nb_steps:		100
pdrop:		0.1
normalization:		batchnorm
use_bias:		False
bidirectional:		False
date:		07-27-18-28
use_pretrained_model:		False
only_do_testing:		False
load_exp_folder:		None
new_exp_folder:		./log/07-27-18-28/
dataset_name:		shd
data_folder:		data/raw/
save_best:		True
batch_size:		128
nb_epochs:		50
dropout:		0.75
dropout_stop:		0.95
dropout_stepping:		0.02
ckpt_freq:		5
start_epoch:		0
lr:		0.01
scheduler_patience:		2
scheduler_factor:		0.7
use_regularizers:		False
reg_factor:		0.5
reg_fmin:		0.01
reg_fmax:		0.1
use_augm:		False
use_readout_layer:		True
threshold:		1.0
device:		cuda

Device is set to cuda

Number of examples in train set: 8156
SHD does not have a validation split. Using test split.
Number of examples in test set: 2264

Created new spiking model:
 SNN(
  (snn): ModuleList(
    (0): RadLIFLayer(
      (W): Linear(in_features=700, out_features=1024, bias=False)
      (V): Linear(in_features=1024, out_features=1024, bias=False)
      (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (1): RadLIFLayer(
      (W): Linear(in_features=1024, out_features=1024, bias=False)
      (V): Linear(in_features=1024, out_features=1024, bias=False)
      (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (2): ReadoutLayer(
      (W): Linear(in_features=1024, out_features=20, bias=False)
      (norm): BatchNorm1d(20, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
  )
)

Total number of trainable parameters is 3895356

------ Begin training ------

Epoch 1: train loss=1.980052636936307, acc=0.4014255689538043, fr=0.081077940762043, lr=0.01, time=0:00:34.097043, cin=0.0037587748374789953, cout=0.018232230097055435
Epoch 1: valid loss=1.5644305282168918, acc=0.5336568813131313, fr=0.09000222384929657, mask=0.875, time=0:00:04.714997

Best model saved with valid acc=0.5336568813131313

-----------------------------

Epoch 2: train loss=0.7034976407885551, acc=0.7634701936141304, fr=0.08565384894609451, lr=0.01, time=0:00:30.998766, cin=0.0038478958886116743, cout=0.041212864220142365
Epoch 2: valid loss=0.7718142304155562, acc=0.7574179292929293, fr=0.09023983031511307, mask=0.8784580230712891, time=0:00:04.360396

Best model saved with valid acc=0.7574179292929293

-----------------------------

Epoch 3: train loss=0.3855784386396408, acc=0.8733281674592391, fr=0.0868854895234108, lr=0.01, time=0:00:31.181027, cin=0.0038622145075351, cout=0.01233608927577734
Epoch 3: valid loss=0.48612834016482037, acc=0.8464330808080809, fr=0.09246758371591568, mask=0.8808841705322266, time=0:00:04.363258

Best model saved with valid acc=0.8464330808080809

-----------------------------

Epoch 4: train loss=0.2739899477455765, acc=0.9088240913722826, fr=0.08871813118457794, lr=0.01, time=0:00:30.938927, cin=0.004934600088745356, cout=0.03167780861258507
Epoch 4: valid loss=0.43827014830377364, acc=0.8652146464646465, fr=0.09455662220716476, mask=0.883303165435791, time=0:00:04.328038

Best model saved with valid acc=0.8652146464646465

-----------------------------

Epoch 5: train loss=0.20831879088655114, acc=0.9343314792798914, fr=0.09071262180805206, lr=0.01, time=0:00:30.978552, cin=0.0028387585189193487, cout=0.03858436271548271
Epoch 5: valid loss=0.3739564965168635, acc=0.8769728535353535, fr=0.09405262023210526, mask=0.8856525421142578, time=0:00:04.452940

Best model saved with valid acc=0.8769728535353535

-----------------------------

Epoch 6: train loss=0.14756008726544678, acc=0.9518565302309783, fr=0.0872005969285965, lr=0.01, time=0:00:31.273483, cin=0.0011955286609008908, cout=0.03203929588198662
Epoch 6: valid loss=0.5895961076021194, acc=0.8412247474747475, fr=0.08950813114643097, mask=0.8879046440124512, time=0:00:04.370686

-----------------------------

Epoch 7: train loss=0.13026993838138878, acc=0.9587190047554348, fr=0.08504896610975266, lr=0.01, time=0:00:31.189348, cin=0.0020162572618573904, cout=0.035143960267305374
Epoch 7: valid loss=0.4243735008769565, acc=0.8824179292929293, fr=0.08901210874319077, mask=0.8901200294494629, time=0:00:04.821362

Best model saved with valid acc=0.8824179292929293

-----------------------------

Epoch 8: train loss=0.10044239193666726, acc=0.9674337635869565, fr=0.08397163450717926, lr=0.01, time=0:00:29.898444, cin=0.003771390300244093, cout=0.01648762635886669
Epoch 8: valid loss=0.3841918938689762, acc=0.8826152146464646, fr=0.08759821951389313, mask=0.8922600746154785, time=0:00:04.229589

Best model saved with valid acc=0.8826152146464646

-----------------------------

Epoch 9: train loss=0.08592769788810983, acc=0.9724651834239131, fr=0.08406837284564972, lr=0.01, time=0:00:29.783818, cin=0.0020266063511371613, cout=0.01888907328248024
Epoch 9: valid loss=0.37931839211119545, acc=0.8908617424242424, fr=0.08835449069738388, mask=0.8943963050842285, time=0:00:04.238307

Best model saved with valid acc=0.8908617424242424

-----------------------------

Epoch 10: train loss=0.07025923988840077, acc=0.9767376443614131, fr=0.08322831988334656, lr=0.01, time=0:00:30.076778, cin=0.0033942495938390493, cout=0.013878666795790195
Epoch 10: valid loss=0.37218625595172244, acc=0.8922032828282828, fr=0.08631475269794464, mask=0.8965234756469727, time=0:00:04.205427

Best model saved with valid acc=0.8922032828282828

-----------------------------

Epoch 11: train loss=0.0650274855142925, acc=0.9783935546875, fr=0.08204253762960434, lr=0.01, time=0:00:30.073022, cin=0.0032815015874803066, cout=0.020391276106238365
Epoch 11: valid loss=0.3076299743519889, acc=0.9125631313131313, fr=0.08599600195884705, mask=0.8985376358032227, time=0:00:04.243922

Best model saved with valid acc=0.9125631313131313

-----------------------------

Epoch 12: train loss=0.05130133737111464, acc=0.9848898182744565, fr=0.0821409672498703, lr=0.01, time=0:00:29.994810, cin=0.002733721164986491, cout=0.019345849752426147
Epoch 12: valid loss=0.2747909579839971, acc=0.9186000631313131, fr=0.08618833124637604, mask=0.9005813598632812, time=0:00:04.324394

Best model saved with valid acc=0.9186000631313131

-----------------------------

Epoch 13: train loss=0.0515019071608549, acc=0.9830109969429348, fr=0.08170831203460693, lr=0.01, time=0:00:30.246299, cin=0.0031509771943092346, cout=0.010181465186178684
Epoch 13: valid loss=0.34628719339768094, acc=0.9214409722222222, fr=0.0851825699210167, mask=0.9025759696960449, time=0:00:04.360577

Best model saved with valid acc=0.9214409722222222

-----------------------------

Epoch 14: train loss=0.034892881601990666, acc=0.9892578125, fr=0.08145161718130112, lr=0.01, time=0:00:30.104883, cin=0.003409705590456724, cout=0.011505408212542534
Epoch 14: valid loss=0.34893131587240434, acc=0.8968986742424243, fr=0.08556074649095535, mask=0.9045219421386719, time=0:00:04.337717

-----------------------------

Epoch 15: train loss=0.03562503845023457, acc=0.9891357421875, fr=0.08186210691928864, lr=0.01, time=0:00:30.410702, cin=0.0033802941907197237, cout=0.00850379467010498
Epoch 15: valid loss=0.4010050387846099, acc=0.90625, fr=0.0864500105381012, mask=0.9064135551452637, time=0:00:04.366667

-----------------------------

Epoch 16: train loss=0.04276047803432448, acc=0.9862591287364131, fr=0.08233088254928589, lr=0.01, time=0:00:31.312056, cin=0.0020969517063349485, cout=0.010820870287716389
Epoch 16: valid loss=0.43856753077771926, acc=0.8752367424242424, fr=0.08539695292711258, mask=0.9082870483398438, time=0:00:04.429273

-----------------------------

Epoch 17: train loss=0.02554890434112167, acc=0.992431640625, fr=0.08158715814352036, lr=0.006999999999999999, time=0:00:31.552614, cin=0.0017042834078893065, cout=0.014268220402300358
Epoch 17: valid loss=0.3124607064657741, acc=0.9175347222222222, fr=0.08542954176664352, mask=0.910062313079834, time=0:00:06.909070

-----------------------------

Epoch 18: train loss=0.022940467544685816, acc=0.9928721552309783, fr=0.08144575357437134, lr=0.006999999999999999, time=0:00:35.768244, cin=0.0020328389946371317, cout=0.00957291666418314
Epoch 18: valid loss=0.3653394604722659, acc=0.9099195075757576, fr=0.08455061167478561, mask=0.9118795394897461, time=0:00:04.374962

-----------------------------

Epoch 19: train loss=0.01928298509301385, acc=0.9933604364809783, fr=0.08061428368091583, lr=0.006999999999999999, time=0:00:30.518182, cin=0.0021927605848759413, cout=0.009558059275150299
Epoch 19: valid loss=0.3166271895170212, acc=0.924636994949495, fr=0.08403266221284866, mask=0.9136614799499512, time=0:00:04.447624

Best model saved with valid acc=0.924636994949495

-----------------------------

Epoch 20: train loss=0.018679005679587135, acc=0.9944113026494565, fr=0.07981918007135391, lr=0.006999999999999999, time=0:00:30.484686, cin=0.0021023706067353487, cout=0.010155772790312767
Epoch 20: valid loss=0.33117512986063957, acc=0.9131549873737375, fr=0.08303402364253998, mask=0.9153790473937988, time=0:00:04.380360

-----------------------------

Epoch 21: train loss=0.014234804248189903, acc=0.9957275390625, fr=0.07929537445306778, lr=0.006999999999999999, time=0:00:30.525772, cin=0.002115254057571292, cout=0.008708177134394646
Epoch 21: valid loss=0.3007659390568733, acc=0.9200994318181819, fr=0.08278553932905197, mask=0.9170279502868652, time=0:00:04.388745

-----------------------------

Epoch 22: train loss=0.014582897219042934, acc=0.9952392578125, fr=0.07923128455877304, lr=0.006999999999999999, time=0:00:30.295413, cin=0.00232275715097785, cout=0.010295741260051727
Epoch 22: valid loss=0.40911417040559983, acc=0.9096827651515151, fr=0.08288578689098358, mask=0.9186725616455078, time=0:00:04.466923

-----------------------------

Epoch 23: train loss=0.011526114461958059, acc=0.99658203125, fr=0.07908450067043304, lr=0.004899999999999999, time=0:00:30.711348, cin=0.002777505200356245, cout=0.011386253871023655
Epoch 23: valid loss=0.2949264082643721, acc=0.9300820707070707, fr=0.08276396989822388, mask=0.9203319549560547, time=0:00:04.421916

Best model saved with valid acc=0.9300820707070707

-----------------------------

Epoch 24: train loss=0.00892894521530252, acc=0.9976806640625, fr=0.07902942597866058, lr=0.004899999999999999, time=0:00:30.433609, cin=0.0031555185560137033, cout=0.010321102105081081
Epoch 24: valid loss=0.2909284341666434, acc=0.9266098484848485, fr=0.08233363926410675, mask=0.9219298362731934, time=0:00:04.465112

-----------------------------

Epoch 25: train loss=0.007453902429006121, acc=0.99853515625, fr=0.07863414287567139, lr=0.004899999999999999, time=0:00:30.781161, cin=0.003219162579625845, cout=0.01145692728459835
Epoch 25: valid loss=0.42525877844956184, acc=0.9122869318181819, fr=0.08212466537952423, mask=0.9234914779663086, time=0:00:04.380717

-----------------------------

Epoch 26: train loss=0.008128765447509068, acc=0.99755859375, fr=0.0783734917640686, lr=0.004899999999999999, time=0:00:30.464252, cin=0.0029065494891256094, cout=0.01251292135566473
Epoch 26: valid loss=0.3773662779066298, acc=0.9157591540404041, fr=0.08186409622430801, mask=0.9250450134277344, time=0:00:04.393524

-----------------------------

Epoch 27: train loss=0.007426627289987664, acc=0.9981689453125, fr=0.07816209644079208, lr=0.003429999999999999, time=0:00:31.501974, cin=0.0034283834975212812, cout=0.014288407750427723
Epoch 27: valid loss=0.3709281227654881, acc=0.9144965277777778, fr=0.08173944801092148, mask=0.9265861511230469, time=0:00:04.589162

-----------------------------

Epoch 28: train loss=0.0057918724733099225, acc=0.9981689453125, fr=0.07795941829681396, lr=0.003429999999999999, time=0:00:30.476970, cin=0.0031972203869372606, cout=0.015205169096589088
Epoch 28: valid loss=0.40695376901162994, acc=0.9274779040404041, fr=0.08156205713748932, mask=0.9280619621276855, time=0:00:04.308801

-----------------------------

Epoch 29: train loss=0.004891559075986152, acc=0.9986572265625, fr=0.07789498567581177, lr=0.003429999999999999, time=0:00:30.568707, cin=0.0027643118519335985, cout=0.011837190948426723
Epoch 29: valid loss=0.4494483959343698, acc=0.9088147095959597, fr=0.08142060786485672, mask=0.9294891357421875, time=0:00:04.443427

-----------------------------

Epoch 30: train loss=0.005210546338730637, acc=0.9989013671875, fr=0.07765256613492966, lr=0.002400999999999999, time=0:00:30.521411, cin=0.0025184513069689274, cout=0.013434848748147488
Epoch 30: valid loss=0.36335929441783166, acc=0.9151278409090909, fr=0.08103101700544357, mask=0.9308791160583496, time=0:00:04.364733

-----------------------------

Epoch 31: train loss=0.0044890067106280185, acc=0.9990234375, fr=0.07736987620592117, lr=0.002400999999999999, time=0:00:30.434816, cin=0.002549749566242099, cout=0.014264759607613087
Epoch 31: valid loss=0.3596780076622963, acc=0.9192313762626263, fr=0.08084612339735031, mask=0.932243824005127, time=0:00:04.446129

-----------------------------

Epoch 32: train loss=0.004303999922740331, acc=0.99853515625, fr=0.07715901732444763, lr=0.002400999999999999, time=0:00:30.703478, cin=0.002458413364365697, cout=0.014754352159798145
Epoch 32: valid loss=0.3008262382613288, acc=0.9309106691919192, fr=0.08060521632432938, mask=0.9335908889770508, time=0:00:04.466188

Best model saved with valid acc=0.9309106691919192

-----------------------------

Epoch 33: train loss=0.00480569621822724, acc=0.9990234375, fr=0.07705153524875641, lr=0.002400999999999999, time=0:00:30.957406, cin=0.002617305377498269, cout=0.011176446452736855
Epoch 33: valid loss=0.40625718360145885, acc=0.913983585858586, fr=0.0806216448545456, mask=0.9349527359008789, time=0:00:04.439085

-----------------------------

Epoch 34: train loss=0.0036121254847785167, acc=0.9991455078125, fr=0.0769013985991478, lr=0.002400999999999999, time=0:00:30.358711, cin=0.0023573192302137613, cout=0.011662610806524754
Epoch 34: valid loss=0.3393123294744227, acc=0.9281486742424243, fr=0.08036553114652634, mask=0.9362878799438477, time=0:00:04.362572

-----------------------------

Epoch 35: train loss=0.004012271571809833, acc=0.9991455078125, fr=0.07659455388784409, lr=0.002400999999999999, time=0:00:30.568666, cin=0.0021060609724372625, cout=0.010383941233158112
Epoch 35: valid loss=0.3651623800396919, acc=0.9242029671717172, fr=0.08002127707004547, mask=0.9375581741333008, time=0:00:04.415344

-----------------------------

Epoch 36: train loss=0.004611375632521231, acc=0.9986572265625, fr=0.07639418542385101, lr=0.0016806999999999992, time=0:00:30.513222, cin=0.0019485296215862036, cout=0.010512023232877254
Epoch 36: valid loss=0.3091132164829307, acc=0.9309501262626263, fr=0.07987520098686218, mask=0.9387903213500977, time=0:00:04.813108

Best model saved with valid acc=0.9309501262626263

-----------------------------

Epoch 37: train loss=0.003631767139040676, acc=0.9991455078125, fr=0.07638517767190933, lr=0.0016806999999999992, time=0:00:34.024315, cin=0.0018142667831853032, cout=0.011465334333479404
Epoch 37: valid loss=0.3866288024518225, acc=0.9215988005050506, fr=0.0798816904425621, mask=0.9399852752685547, time=0:00:06.442811

-----------------------------

Epoch 38: train loss=0.003380539186309761, acc=0.9990977411684783, fr=0.07621590048074722, lr=0.0016806999999999992, time=0:00:35.464631, cin=0.0020319409668445587, cout=0.010138183832168579
Epoch 38: valid loss=0.37473709094855523, acc=0.9298058712121213, fr=0.07962910830974579, mask=0.9411959648132324, time=0:00:05.251198

-----------------------------

Epoch 39: train loss=0.002965632485029346, acc=0.9996337890625, fr=0.07596800476312637, lr=0.0011764899999999994, time=0:00:36.171289, cin=0.0020111403428018093, cout=0.010650050826370716
Epoch 39: valid loss=0.3581096674833033, acc=0.9196654040404041, fr=0.07943859696388245, mask=0.9423828125, time=0:00:05.266608

-----------------------------

Epoch 40: train loss=0.002310672241037537, acc=0.9996337890625, fr=0.07576275616884232, lr=0.0011764899999999994, time=0:00:33.876823, cin=0.0018843250581994653, cout=0.009667736478149891
Epoch 40: valid loss=0.3498857302798165, acc=0.9240056818181819, fr=0.07910014688968658, mask=0.9435238838195801, time=0:00:04.674345

-----------------------------

Epoch 41: train loss=0.0034215987857351138, acc=0.99951171875, fr=0.07547614723443985, lr=0.0011764899999999994, time=0:00:33.211348, cin=0.0021257956977933645, cout=0.010053814388811588
Epoch 41: valid loss=0.32537831241885823, acc=0.9281092171717172, fr=0.07885143160820007, mask=0.9446449279785156, time=0:00:04.766681

-----------------------------

Epoch 42: train loss=0.0028150949369774025, acc=0.9996337890625, fr=0.07520736753940582, lr=0.0008235429999999996, time=0:00:34.222827, cin=0.002052269410341978, cout=0.00867514405399561
Epoch 42: valid loss=0.3470322858128283, acc=0.9254655934343435, fr=0.07864422351121902, mask=0.9457287788391113, time=0:00:04.837251

-----------------------------

Epoch 43: train loss=0.0036228983587989205, acc=0.999267578125, fr=0.07500779628753662, lr=0.0008235429999999996, time=0:00:34.250470, cin=0.0019581448286771774, cout=0.008153405040502548
Epoch 43: valid loss=0.31731045701437527, acc=0.9190340909090909, fr=0.07847113162279129, mask=0.9468245506286621, time=0:00:04.878974

-----------------------------

Epoch 44: train loss=0.0032906909746088786, acc=0.9991455078125, fr=0.07481379806995392, lr=0.0008235429999999996, time=0:00:33.796112, cin=0.002055421704426408, cout=0.008234603330492973
Epoch 44: valid loss=0.34702445649438435, acc=0.9174952651515151, fr=0.078196220099926, mask=0.9478530883789062, time=0:00:05.061140

-----------------------------

Epoch 45: train loss=0.0023597826616423845, acc=0.9998779296875, fr=0.07450440526008606, lr=0.0005764800999999997, time=0:00:32.335029, cin=0.0020232531242072582, cout=0.00659980671480298
Epoch 45: valid loss=0.31699392903182244, acc=0.9255050505050506, fr=0.07785933464765549, mask=0.948854923248291, time=0:00:04.735655

-----------------------------

Epoch 46: train loss=0.0028130436221545096, acc=0.999267578125, fr=0.0742688700556755, lr=0.0005764800999999997, time=0:00:34.102341, cin=0.0019299316918477416, cout=0.006460960488766432
Epoch 46: valid loss=0.3477717828419473, acc=0.9257417929292929, fr=0.07757047563791275, mask=0.9498233795166016, time=0:00:04.564050

-----------------------------

Epoch 47: train loss=0.003374314286702429, acc=0.9988536005434783, fr=0.07394564896821976, lr=0.0005764800999999997, time=0:00:34.664820, cin=0.0016871222760528326, cout=0.006531282793730497
Epoch 47: valid loss=0.3263023520509402, acc=0.9270044191919192, fr=0.07720735669136047, mask=0.950833797454834, time=0:00:04.748495

-----------------------------

Epoch 48: train loss=0.003335600858918042, acc=0.999267578125, fr=0.07393959164619446, lr=0.00040353606999999974, time=0:00:35.140391, cin=0.0016867156373336911, cout=0.006494949571788311
Epoch 48: valid loss=0.3381868584288491, acc=0.9248342803030304, fr=0.07726874947547913, mask=0.950833797454834, time=0:00:04.790553

-----------------------------

Epoch 49: train loss=0.0028776373324035376, acc=0.9993896484375, fr=0.07395759969949722, lr=0.00040353606999999974, time=0:00:32.181701, cin=0.001689927070401609, cout=0.0065828715451061726
Epoch 49: valid loss=0.37006176594230866, acc=0.9205334595959597, fr=0.07723922282457352, mask=0.950833797454834, time=0:00:05.178015

-----------------------------

Epoch 50: train loss=0.002530949985384723, acc=0.99951171875, fr=0.0739627406001091, lr=0.00040353606999999974, time=0:00:35.297554, cin=0.001673325663432479, cout=0.0064819627441465855
Epoch 50: valid loss=0.3555595266322295, acc=0.921796085858586, fr=0.0773545503616333, mask=0.950833797454834, time=0:00:05.728429

-----------------------------


Best valid acc at epoch 36: 0.9309501262626263


------ Training finished ------

Loading best model, epoch=36, valid acc=0.9309501262626263

------ Begin Testing ------

Test loss=0.32850826117727494, acc=0.9155224116161617, mean act rate=0.07680639624595642

-----------------------------


This dataset uses the same split for validation and testing.

