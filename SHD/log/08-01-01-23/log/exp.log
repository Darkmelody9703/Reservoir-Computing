===== Exp configuration =====
neuron_type:		RadLIF
nb_inputs:		700
nb_outputs:		20
nb_layers:		3
nb_hiddens:		1024
nb_steps:		100
pdrop:		0.1
normalization:		batchnorm
use_bias:		False
bidirectional:		False
date:		08-01-01-23
use_pretrained_model:		False
only_do_testing:		False
load_exp_folder:		None
new_exp_folder:		./log/08-01-01-23
dataset_name:		shd
data_folder:		./data/raw/
batch_size:		128
nb_epochs:		30
train_input_layer:		True
trial:		5
seed:		1690824203
dropout:		0.75
dropout_stop:		0.95
dropout_stepping:		0.0
ckpt_freq:		5
clustering:		True
clustering_factor:		[0.1, 0.25]
cin_minmax:		[0.001, 0.05]
cout_minmax:		[0.05, 0.2]
nb_cluster:		8
nb_per_cluster:		128
noise_test:		0.2
start_epoch:		0
lr:		0.01
scheduler_patience:		2
scheduler_factor:		0.7
use_regularizers:		False
reg_factor:		0.5
reg_fmin:		0.01
reg_fmax:		0.1
use_augm:		False
use_readout_layer:		True
threshold:		1.0
device:		cuda

Device is set to cuda
checkpoint_dir: ./log/08-01-01-23/checkpoints/

Number of examples in train set: 8156
SHD does not have a validation split. Using test split.
Number of examples in test set: 2264

Created new spiking model:
 SNN(
  (snn): ModuleList(
    (0): RadLIFLayer(
      (W): Linear(in_features=700, out_features=1024, bias=False)
      (V): Linear(in_features=1024, out_features=1024, bias=False)
      (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (1): RadLIFLayer(
      (W): Linear(in_features=1024, out_features=1024, bias=False)
      (V): Linear(in_features=1024, out_features=1024, bias=False)
      (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (2): ReadoutLayer(
      (W): Linear(in_features=1024, out_features=20, bias=False)
      (norm): BatchNorm1d(20, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
  )
)

Total number of trainable parameters is 3895356

---------------Trial:1---------------


------ Begin training ------

Epoch 1: train loss=9.1376, acc=0.0466, fr=0.0628, lr=0.0100, time=34.026432, cin=0.000134, 0.000072, cout=0.005740, 0.007192
Epoch 1: valid loss=5.1020, acc=0.0528, fr=0.0641, mask=0.8750, time=05.752482

Best model saved with valid acc=0.052754103535353536

-----------------------------

Epoch 2: train loss=9.0990, acc=0.0512, fr=0.0627, lr=0.0100, time=34.065516, cin=0.000126, 0.000062, cout=0.005513, 0.006869
Epoch 2: valid loss=8.7571, acc=0.0551, fr=0.0662, mask=0.8760, time=06.346059

Best model saved with valid acc=0.055082070707070704

-----------------------------

Epoch 3: train loss=9.0568, acc=0.0488, fr=0.0627, lr=0.0100, time=31.817796, cin=0.000126, 0.000062, cout=0.005513, 0.006869
Epoch 3: valid loss=9.4019, acc=0.0498, fr=0.0664, mask=0.8760, time=05.783683

-----------------------------

Epoch 4: train loss=9.0792, acc=0.0479, fr=0.0627, lr=0.0100, time=32.240359, cin=0.000126, 0.000062, cout=0.005513, 0.006869
Epoch 4: valid loss=9.1069, acc=0.0519, fr=0.0665, mask=0.8760, time=05.821477

-----------------------------

Epoch 5: train loss=8.9975, acc=0.0505, fr=0.0628, lr=0.0100, time=31.927134, cin=0.000126, 0.000062, cout=0.005513, 0.006869
Epoch 5: valid loss=9.2066, acc=0.0498, fr=0.0665, mask=0.8760, time=05.682065

-----------------------------

Epoch 6: train loss=9.0405, acc=0.0471, fr=0.0627, lr=0.0070, time=31.241797, cin=0.000126, 0.000062, cout=0.005513, 0.006869
Epoch 6: valid loss=9.3900, acc=0.0509, fr=0.0665, mask=0.8760, time=05.716523

-----------------------------

Epoch 7: train loss=9.1017, acc=0.0432, fr=0.0627, lr=0.0070, time=32.205821, cin=0.000126, 0.000062, cout=0.005513, 0.006869
Epoch 7: valid loss=9.1469, acc=0.0403, fr=0.0665, mask=0.8760, time=05.889983

-----------------------------

Epoch 8: train loss=9.1521, acc=0.0453, fr=0.0627, lr=0.0070, time=30.836545, cin=0.000126, 0.000062, cout=0.005513, 0.006869
