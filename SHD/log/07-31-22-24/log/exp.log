===== Exp configuration =====
neuron_type:		RadLIF
nb_inputs:		700
nb_outputs:		20
nb_layers:		3
nb_hiddens:		1024
nb_steps:		100
pdrop:		0.1
normalization:		batchnorm
use_bias:		False
bidirectional:		False
date:		07-31-22-24
use_pretrained_model:		False
only_do_testing:		False
load_exp_folder:		None
new_exp_folder:		./log/07-31-22-24
dataset_name:		shd
data_folder:		./data/raw/
batch_size:		128
nb_epochs:		30
train_input_layer:		True
trial:		5
seed:		1690813489
dropout:		0.75
dropout_stop:		0.95
dropout_stepping:		0.0
ckpt_freq:		5
clustering:		False
clustering_factor:		[0.1, 0.25]
cin_minmax:		[0.001, 0.05]
cout_minmax:		[0.05, 0.2]
nb_cluster:		8
nb_per_cluster:		128
noise_test:		0.2
start_epoch:		0
lr:		0.01
scheduler_patience:		2
scheduler_factor:		0.7
use_regularizers:		False
reg_factor:		0.5
reg_fmin:		0.01
reg_fmax:		0.1
use_augm:		False
use_readout_layer:		True
threshold:		1.0
device:		cuda

Device is set to cuda
checkpoint_dir: ./log/07-31-22-24/checkpoints/

Number of examples in train set: 8156
SHD does not have a validation split. Using test split.
Number of examples in test set: 2264

Created new spiking model:
 SNN(
  (snn): ModuleList(
    (0): RadLIFLayer(
      (W): Linear(in_features=700, out_features=1024, bias=False)
      (V): Linear(in_features=1024, out_features=1024, bias=False)
      (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (1): RadLIFLayer(
      (W): Linear(in_features=1024, out_features=1024, bias=False)
      (V): Linear(in_features=1024, out_features=1024, bias=False)
      (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (2): ReadoutLayer(
      (W): Linear(in_features=1024, out_features=20, bias=False)
      (norm): BatchNorm1d(20, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
  )
)

Total number of trainable parameters is 3895356

---------------Trial:1---------------


------ Begin training ------

Epoch 1: train loss=9.1625, acc=0.0498, fr=0.0583, lr=0.0100, time=33.448849, cin=0.000055, 0.000098, cout=0.001907, 0.004561
Epoch 1: valid loss=4.9549, acc=0.0516, fr=0.0590, mask=0.8750, time=05.906060

Best model saved with valid acc=0.05157039141414141

-----------------------------

Epoch 2: train loss=9.2097, acc=0.0478, fr=0.0584, lr=0.0100, time=30.256921, cin=0.000045, 0.000097, cout=0.002564, 0.004970
Epoch 2: valid loss=8.8462, acc=0.0460, fr=0.0608, mask=0.8760, time=06.321791

-----------------------------

Epoch 3: train loss=9.0275, acc=0.0515, fr=0.0583, lr=0.0100, time=32.047539, cin=0.000045, 0.000097, cout=0.002564, 0.004970
Epoch 3: valid loss=9.2385, acc=0.0474, fr=0.0610, mask=0.8760, time=07.275179

-----------------------------

Epoch 4: train loss=9.0882, acc=0.0535, fr=0.0584, lr=0.0100, time=31.065043, cin=0.000045, 0.000097, cout=0.002564, 0.004970
Epoch 4: valid loss=9.1693, acc=0.0537, fr=0.0611, mask=0.8760, time=06.170494

Best model saved with valid acc=0.053740530303030304

-----------------------------

Epoch 5: train loss=9.1126, acc=0.0500, fr=0.0583, lr=0.0100, time=31.303149, cin=0.000045, 0.000097, cout=0.002564, 0.004970
Epoch 5: valid loss=9.1448, acc=0.0587, fr=0.0609, mask=0.8760, time=06.352333

Best model saved with valid acc=0.058712121212121215

-----------------------------

Epoch 6: train loss=9.1396, acc=0.0510, fr=0.0583, lr=0.0100, time=30.986286, cin=0.000045, 0.000097, cout=0.002564, 0.004970
Epoch 6: valid loss=9.2993, acc=0.0472, fr=0.0610, mask=0.8760, time=06.211540

-----------------------------

Epoch 7: train loss=9.1440, acc=0.0492, fr=0.0584, lr=0.0100, time=53.491268, cin=0.000045, 0.000097, cout=0.002564, 0.004970
Epoch 7: valid loss=9.1958, acc=0.0505, fr=0.0611, mask=0.8760, time=06.356128

-----------------------------

