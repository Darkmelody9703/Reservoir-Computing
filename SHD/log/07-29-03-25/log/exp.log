===== Exp configuration =====
neuron_type:		RadLIF
nb_inputs:		700
nb_outputs:		20
nb_layers:		3
nb_hiddens:		1024
nb_steps:		100
pdrop:		0.1
normalization:		batchnorm
use_bias:		False
bidirectional:		False
date:		07-29-03-25
use_pretrained_model:		False
only_do_testing:		False
load_exp_folder:		None
new_exp_folder:		./log/07-29-03-25/
dataset_name:		shd
data_folder:		data/raw/
batch_size:		128
nb_epochs:		50
dropout:		0.75
dropout_stop:		0.95
dropout_stepping:		0.02
ckpt_freq:		5
noise_test:		0.2
start_epoch:		0
lr:		0.01
scheduler_patience:		2
scheduler_factor:		0.7
use_regularizers:		False
reg_factor:		0.5
reg_fmin:		0.01
reg_fmax:		0.1
use_augm:		False
use_readout_layer:		True
threshold:		1.0
device:		cuda

Device is set to cuda

Number of examples in train set: 8156
SHD does not have a validation split. Using test split.
Number of examples in test set: 2264

Created new spiking model:
 SNN(
  (snn): ModuleList(
    (0): RadLIFLayer(
      (W): Linear(in_features=700, out_features=1024, bias=False)
      (V): Linear(in_features=1024, out_features=1024, bias=False)
      (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (1): RadLIFLayer(
      (W): Linear(in_features=1024, out_features=1024, bias=False)
      (V): Linear(in_features=1024, out_features=1024, bias=False)
      (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (2): ReadoutLayer(
      (W): Linear(in_features=1024, out_features=20, bias=False)
      (norm): BatchNorm1d(20, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
  )
)

Total number of trainable parameters is 3895356

------ Begin training ------

Epoch 1: train loss=1.9609, acc=0.4142, fr=0.0698, lr=0.0100,                      time=0:00:33.778717, cin=0.003621, 0.006030, cout=0.012660, 0.023097
Epoch 1: valid loss=2.2299704551696777, acc=0.43252840909090906, fr=0.07886965572834015, mask=0.875, time=0:00:05.620092

Best model saved with valid acc=0.43252840909090906

-----------------------------

Epoch 2: train loss=0.5819, acc=0.8097, fr=0.0737, lr=0.0100,                      time=0:00:30.529934, cin=0.004754, 0.003432, cout=0.009964, 0.015989
Epoch 2: valid loss=0.7971077230241563, acc=0.7391098484848485, fr=0.0790788009762764, mask=0.8784656524658203, time=0:00:05.471015

Best model saved with valid acc=0.7391098484848485

-----------------------------

Epoch 3: train loss=0.2843, acc=0.9084, fr=0.0730, lr=0.0100,                      time=0:00:30.193214, cin=0.001296, 0.002760, cout=0.012965, 0.013885
Epoch 3: valid loss=0.6411982708507113, acc=0.8087121212121212, fr=0.07852572947740555, mask=0.8809890747070312, time=0:00:05.616921

Best model saved with valid acc=0.8087121212121212

-----------------------------

Epoch 4: train loss=0.1898, acc=0.9394, fr=0.0742, lr=0.0100,                      time=0:00:30.499775, cin=0.001968, 0.002120, cout=0.008866, 0.011726
Epoch 4: valid loss=0.5419928050703473, acc=0.8302162247474747, fr=0.08042362332344055, mask=0.8833703994750977, time=0:00:05.564232

Best model saved with valid acc=0.8302162247474747

-----------------------------

Epoch 5: train loss=0.1531, acc=0.9532, fr=0.0726, lr=0.0100,                      time=0:00:30.475663, cin=0.002006, 0.002427, cout=0.010299, 0.011160
Epoch 5: valid loss=0.5288047045469284, acc=0.8477351641414141, fr=0.07823513448238373, mask=0.8857417106628418, time=0:00:05.840347

Best model saved with valid acc=0.8477351641414141

-----------------------------

Epoch 6: train loss=0.0965, acc=0.9704, fr=0.0727, lr=0.0100,                      time=0:00:30.572065, cin=0.001650, 0.003692, cout=0.010467, 0.011876
Epoch 6: valid loss=0.4090258288714621, acc=0.8765388257575757, fr=0.07868988066911697, mask=0.8879876136779785, time=0:00:06.213529

Best model saved with valid acc=0.8765388257575757

-----------------------------

Epoch 7: train loss=0.0744, acc=0.9780, fr=0.0724, lr=0.0100,                      time=0:00:34.861625, cin=0.001420, 0.003541, cout=0.020578, 0.011597
Epoch 7: valid loss=0.6029262012905545, acc=0.8476957070707071, fr=0.07726963609457016, mask=0.8902573585510254, time=0:00:06.401290

-----------------------------

Epoch 8: train loss=0.0580, acc=0.9811, fr=0.0706, lr=0.0100,                      time=0:00:31.915905, cin=0.003008, 0.003963, cout=0.013461, 0.011499
Epoch 8: valid loss=1.1056978404521942, acc=0.78125, fr=0.07629093527793884, mask=0.8924856185913086, time=0:00:05.742232

-----------------------------

Epoch 9: train loss=0.0617, acc=0.9804, fr=0.0703, lr=0.0100,                      time=0:00:34.109263, cin=0.002147, 0.002831, cout=0.018207, 0.008858
Epoch 9: valid loss=0.3776409609450234, acc=0.8865214646464646, fr=0.07641983777284622, mask=0.8946099281311035, time=0:00:07.932266

Best model saved with valid acc=0.8865214646464646

-----------------------------

Epoch 10: train loss=0.0479, acc=0.9848, fr=0.0693, lr=0.0100,                      time=0:00:39.068983, cin=0.005798, 0.001696, cout=0.032250, 0.009248
Epoch 10: valid loss=0.5977746645609537, acc=0.850457702020202, fr=0.07349352538585663, mask=0.8967375755310059, time=0:00:06.150688

-----------------------------

Epoch 11: train loss=0.0402, acc=0.9875, fr=0.0674, lr=0.0100,                      time=0:00:31.955215, cin=0.006326, 0.001297, cout=0.029696, 0.009394
Epoch 11: valid loss=0.5863548252317641, acc=0.8483664772727273, fr=0.0734100192785263, mask=0.8988003730773926, time=0:00:05.755394

-----------------------------

Epoch 12: train loss=0.0375, acc=0.9894, fr=0.0669, lr=0.0100,                      time=0:00:30.514606, cin=0.005150, 0.000940, cout=0.027831, 0.008175
Epoch 12: valid loss=0.7992693434158961, acc=0.8207859848484849, fr=0.07244738191366196, mask=0.9008183479309082, time=0:00:05.676758

-----------------------------

Epoch 13: train loss=0.0299, acc=0.9910, fr=0.0667, lr=0.0070,                      time=0:00:30.589469, cin=0.005926, 0.001135, cout=0.025878, 0.008498
Epoch 13: valid loss=0.5365292247798708, acc=0.8613873106060607, fr=0.07212655991315842, mask=0.9027414321899414, time=0:00:05.752282

-----------------------------

Epoch 14: train loss=0.0137, acc=0.9963, fr=0.0665, lr=0.0070,                      time=0:00:31.245110, cin=0.005036, 0.001274, cout=0.028982, 0.008199
Epoch 14: valid loss=0.3674637923638026, acc=0.8995028409090909, fr=0.07210367172956467, mask=0.9047341346740723, time=0:00:05.869171

Best model saved with valid acc=0.8995028409090909

-----------------------------

Epoch 15: train loss=0.0141, acc=0.9968, fr=0.0669, lr=0.0070,                      time=0:00:31.611564, cin=0.004221, 0.001385, cout=0.024846, 0.006838
Epoch 15: valid loss=0.4458935111761093, acc=0.883917297979798, fr=0.07287947833538055, mask=0.906623363494873, time=0:00:05.748464

-----------------------------

Epoch 16: train loss=0.0101, acc=0.9973, fr=0.0663, lr=0.0070,                      time=0:00:35.262319, cin=0.003660, 0.001662, cout=0.026650, 0.007193
Epoch 16: valid loss=0.3848726741141743, acc=0.8893229166666666, fr=0.07164479792118073, mask=0.9084901809692383, time=0:00:06.024714

-----------------------------

Epoch 17: train loss=0.0125, acc=0.9967, fr=0.0655, lr=0.0070,                      time=0:00:34.383860, cin=0.003897, 0.001397, cout=0.024792, 0.007710
Epoch 17: valid loss=0.6396710375944773, acc=0.8628472222222222, fr=0.07282726466655731, mask=0.9103002548217773, time=0:00:06.108243

-----------------------------

Epoch 18: train loss=0.0124, acc=0.9963, fr=0.0664, lr=0.0049,                      time=0:00:30.918603, cin=0.003666, 0.001232, cout=0.025878, 0.006447
Epoch 18: valid loss=0.41746282825867337, acc=0.8990688131313131, fr=0.07256840914487839, mask=0.9120960235595703, time=0:00:05.839092

-----------------------------

Epoch 19: train loss=0.0103, acc=0.9972, fr=0.0663, lr=0.0049,                      time=0:00:30.857586, cin=0.002754, 0.001028, cout=0.024789, 0.006642
Epoch 19: valid loss=0.5154967738522424, acc=0.8843118686868687, fr=0.07253863662481308, mask=0.9138660430908203, time=0:00:05.674855

-----------------------------

Epoch 20: train loss=0.0052, acc=0.9986, fr=0.0663, lr=0.0049,                      time=0:00:30.806641, cin=0.002957, 0.001298, cout=0.025231, 0.006755
Epoch 20: valid loss=0.6098496632443534, acc=0.8661616161616162, fr=0.07227795571088791, mask=0.915583610534668, time=0:00:05.882898

-----------------------------

Epoch 21: train loss=0.0037, acc=0.9995, fr=0.0659, lr=0.0034,                      time=0:00:30.656645, cin=0.002867, 0.001183, cout=0.025493, 0.007262
Epoch 21: valid loss=0.5029242742392752, acc=0.883404356060606, fr=0.07179396599531174, mask=0.9172658920288086, time=0:00:05.728853

-----------------------------

Epoch 22: train loss=0.0032, acc=0.9995, fr=0.0656, lr=0.0034,                      time=0:00:30.687835, cin=0.002472, 0.001167, cout=0.024988, 0.007325
Epoch 22: valid loss=0.6489622063106961, acc=0.8682528409090909, fr=0.07184991240501404, mask=0.9189567565917969, time=0:00:05.892359

-----------------------------

Epoch 23: train loss=0.0036, acc=0.9993, fr=0.0657, lr=0.0034,                      time=0:00:31.019948, cin=0.002425, 0.001213, cout=0.025835, 0.006955
Epoch 23: valid loss=0.7395706176757812, acc=0.8591382575757576, fr=0.07180038839578629, mask=0.9205670356750488, time=0:00:05.965625

-----------------------------

Epoch 24: train loss=0.0025, acc=0.9995, fr=0.0656, lr=0.0024,                      time=0:00:31.408472, cin=0.002375, 0.001165, cout=0.025536, 0.007093
Epoch 24: valid loss=0.5670432166920768, acc=0.8745265151515151, fr=0.07163987308740616, mask=0.9222192764282227, time=0:00:06.229637

-----------------------------

Epoch 25: train loss=0.0025, acc=0.9995, fr=0.0653, lr=0.0024,                      time=0:00:31.115715, cin=0.002547, 0.001056, cout=0.025906, 0.006781
Epoch 25: valid loss=0.5651740580797195, acc=0.8764993686868687, fr=0.07149656862020493, mask=0.9237985610961914, time=0:00:05.782992

-----------------------------

Epoch 26: train loss=0.0021, acc=0.9999, fr=0.0650, lr=0.0024,                      time=0:00:30.919984, cin=0.002336, 0.001116, cout=0.026027, 0.007130
Epoch 26: valid loss=0.5656746178865433, acc=0.8827730429292929, fr=0.07109404355287552, mask=0.9252986907958984, time=0:00:05.783080

-----------------------------

Epoch 27: train loss=0.0021, acc=0.9996, fr=0.0647, lr=0.0017,                      time=0:00:31.254423, cin=0.002290, 0.001181, cout=0.024278, 0.006797
Epoch 27: valid loss=0.5889417065514458, acc=0.8775647095959597, fr=0.07095836102962494, mask=0.926816463470459, time=0:00:05.883155

-----------------------------

Epoch 28: train loss=0.0023, acc=0.9998, fr=0.0646, lr=0.0017,                      time=0:00:31.005796, cin=0.002224, 0.001057, cout=0.024099, 0.007394
Epoch 28: valid loss=0.5789379278818766, acc=0.8758285984848485, fr=0.07080775499343872, mask=0.9282650947570801, time=0:00:05.914929

-----------------------------

Epoch 29: train loss=0.0018, acc=1.0000, fr=0.0643, lr=0.0017,                      time=0:00:30.924003, cin=0.002221, 0.001014, cout=0.023214, 0.007722
Epoch 29: valid loss=0.6078575799862543, acc=0.8728298611111112, fr=0.0705389454960823, mask=0.9296889305114746, time=0:00:05.847417

-----------------------------

Epoch 30: train loss=0.0016, acc=1.0000, fr=0.0641, lr=0.0012,                      time=0:00:30.896266, cin=0.001996, 0.001116, cout=0.022704, 0.007218
Epoch 30: valid loss=0.5993621812926399, acc=0.8765388257575757, fr=0.07044632732868195, mask=0.9311008453369141, time=0:00:05.804923

-----------------------------

Epoch 31: train loss=0.0020, acc=0.9996, fr=0.0639, lr=0.0012,                      time=0:00:30.610339, cin=0.001901, 0.001144, cout=0.023408, 0.007678
Epoch 31: valid loss=0.5501064525710212, acc=0.8748027146464646, fr=0.0700138658285141, mask=0.9325056076049805, time=0:00:05.945450

-----------------------------

Epoch 32: train loss=0.0023, acc=0.9996, fr=0.0636, lr=0.0012,                      time=0:00:31.296525, cin=0.002006, 0.001015, cout=0.024394, 0.007312
Epoch 32: valid loss=0.6092173738612069, acc=0.8753945707070707, fr=0.07011168450117111, mask=0.9338555335998535, time=0:00:05.698157

-----------------------------

Epoch 33: train loss=0.0030, acc=0.9993, fr=0.0635, lr=0.0008,                      time=0:00:31.109812, cin=0.001951, 0.001061, cout=0.023235, 0.007367
Epoch 33: valid loss=0.5884111937549379, acc=0.8732638888888888, fr=0.06983280926942825, mask=0.9351596832275391, time=0:00:05.924437

-----------------------------

Epoch 34: train loss=0.0019, acc=0.9998, fr=0.0633, lr=0.0008,                      time=0:00:30.965212, cin=0.001971, 0.000993, cout=0.022278, 0.007253
Epoch 34: valid loss=0.596917986869812, acc=0.8759075126262625, fr=0.06989613175392151, mask=0.9364638328552246, time=0:00:05.819295

-----------------------------

Epoch 35: train loss=0.0018, acc=0.9996, fr=0.0633, lr=0.0008,                      time=0:00:31.262955, cin=0.001917, 0.000818, cout=0.022139, 0.008077
Epoch 35: valid loss=0.6700692209932539, acc=0.8665167297979798, fr=0.06988938897848129, mask=0.9376835823059082, time=0:00:06.065267

-----------------------------

Epoch 36: train loss=0.0015, acc=0.9998, fr=0.0632, lr=0.0006,                      time=0:00:30.883679, cin=0.002088, 0.000869, cout=0.021228, 0.008171
Epoch 36: valid loss=0.6020313219891654, acc=0.8725536616161615, fr=0.06959126889705658, mask=0.9389262199401855, time=0:00:05.931147

-----------------------------

Epoch 37: train loss=0.0018, acc=0.9998, fr=0.0630, lr=0.0006,                      time=0:00:31.180449, cin=0.001685, 0.000812, cout=0.018694, 0.007676
Epoch 37: valid loss=0.5503357864088483, acc=0.8819444444444444, fr=0.06960348784923553, mask=0.940147876739502, time=0:00:05.928159

-----------------------------

Epoch 38: train loss=0.0014, acc=1.0000, fr=0.0629, lr=0.0006,                      time=0:00:31.082197, cin=0.001611, 0.000797, cout=0.019301, 0.007765
Epoch 38: valid loss=0.5769758390055763, acc=0.8775252525252525, fr=0.06945767253637314, mask=0.9413375854492188, time=0:00:05.898683

-----------------------------

Epoch 39: train loss=0.0017, acc=0.9998, fr=0.0628, lr=0.0004,                      time=0:00:30.876931, cin=0.001565, 0.000794, cout=0.019856, 0.008885
Epoch 39: valid loss=0.57275147901641, acc=0.8760653409090909, fr=0.06936027854681015, mask=0.9425210952758789, time=0:00:05.947743

-----------------------------

Epoch 40: train loss=0.0016, acc=0.9999, fr=0.0624, lr=0.0004,                      time=0:00:31.103389, cin=0.001315, 0.000756, cout=0.018014, 0.009285
Epoch 40: valid loss=0.5957146998908784, acc=0.8726325757575757, fr=0.06895025819540024, mask=0.9436583518981934, time=0:00:05.749141

-----------------------------

Epoch 41: train loss=0.0029, acc=0.9995, fr=0.0623, lr=0.0004,                      time=0:00:32.998806, cin=0.001315, 0.000894, cout=0.016151, 0.008692
Epoch 41: valid loss=0.6230905122227139, acc=0.8676215277777778, fr=0.06887707859277725, mask=0.9447989463806152, time=0:00:06.626193

-----------------------------

Epoch 42: train loss=0.0014, acc=1.0000, fr=0.0621, lr=0.0003,                      time=0:00:34.485105, cin=0.001508, 0.000851, cout=0.015703, 0.007970
Epoch 42: valid loss=0.6003633605109321, acc=0.8760258838383838, fr=0.0686684250831604, mask=0.9459147453308105, time=0:00:05.991717

-----------------------------

Epoch 43: train loss=0.0016, acc=0.9997, fr=0.0620, lr=0.0003,                      time=0:00:30.765545, cin=0.001523, 0.000747, cout=0.015417, 0.007554
Epoch 43: valid loss=0.5985019703706106, acc=0.8717645202020202, fr=0.06854066997766495, mask=0.9470195770263672, time=0:00:05.768842

-----------------------------

Epoch 44: train loss=0.0017, acc=0.9999, fr=0.0617, lr=0.0003,                      time=0:00:30.948310, cin=0.001710, 0.000681, cout=0.015632, 0.007087
Epoch 44: valid loss=0.6144062313768599, acc=0.8702256944444444, fr=0.06833194196224213, mask=0.9481091499328613, time=0:00:05.892069

-----------------------------

Epoch 45: train loss=0.0019, acc=1.0000, fr=0.0615, lr=0.0002,                      time=0:00:30.896495, cin=0.001564, 0.000710, cout=0.015685, 0.007755
Epoch 45: valid loss=0.6104664239618514, acc=0.8669507575757576, fr=0.0680454820394516, mask=0.9491643905639648, time=0:00:05.899504

-----------------------------

Epoch 46: train loss=0.0024, acc=0.9999, fr=0.0614, lr=0.0002,                      time=0:00:30.900196, cin=0.001529, 0.000679, cout=0.014773, 0.007877
Epoch 46: valid loss=0.595312785771158, acc=0.8708570075757576, fr=0.06804470717906952, mask=0.950225830078125, time=0:00:05.862079

-----------------------------

Epoch 47: train loss=0.0024, acc=0.9995, fr=0.0614, lr=0.0002,                      time=0:00:34.741965, cin=0.001537, 0.000678, cout=0.014667, 0.007880
Epoch 47: valid loss=0.552208188507292, acc=0.8741319444444444, fr=0.06797999888658524, mask=0.950225830078125, time=0:00:07.602809

-----------------------------

Epoch 48: train loss=0.0017, acc=0.9999, fr=0.0614, lr=0.0001,                      time=0:00:34.796537, cin=0.001536, 0.000679, cout=0.014686, 0.007869
Epoch 48: valid loss=0.5673005597458946, acc=0.8669507575757576, fr=0.06796183437108994, mask=0.950225830078125, time=0:00:07.051046

-----------------------------

Epoch 49: train loss=0.0023, acc=0.9995, fr=0.0614, lr=0.0001,                      time=0:00:35.135756, cin=0.001542, 0.000681, cout=0.014743, 0.007883
Epoch 49: valid loss=0.5597771373060014, acc=0.8760653409090909, fr=0.06804139167070389, mask=0.950225830078125, time=0:00:06.265499

-----------------------------

Epoch 50: train loss=0.0025, acc=0.9994, fr=0.0614, lr=0.0001,                      time=0:00:32.206241, cin=0.001548, 0.000685, cout=0.014775, 0.007881
Epoch 50: valid loss=0.5820754484997855, acc=0.87109375, fr=0.06800960749387741, mask=0.950225830078125, time=0:00:05.840169

-----------------------------


Best valid acc at epoch 14: 0.8995028409090909


------ Training finished ------

