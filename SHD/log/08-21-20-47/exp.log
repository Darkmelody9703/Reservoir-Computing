===== Exp configuration =====
date:		08-21-20-47
save_dir:		./log/08-21-20-47
dataset_name:		shd
data_folder:		./data/raw/
input_dim:		700
output_dim:		20
nb_steps:		100
trials:		5
scheduler_patience:		20
scheduler_factor:		0.7
batch_size:		512
nb_epochs:		100
lr:		0.015
weight_decay:		1e-05
reg_factor:		0.5
reg_fmin:		0.01
reg_fmax:		0.1
fr_ent:		0.1
seed:		1692622029
ckpt_freq:		10
threshold:		1.0
smoothing:		0.1
pdrop:		0.1
normalization:		batchnorm
train_input:		True
nb_hiddens:		1024
noise_test:		0.0
device:		cuda:0

Created new spiking model:
 RC(
  (W): Linear(in_features=700, out_features=1024, bias=True)
  (V): Linear(in_features=1024, out_features=1024, bias=False)
  (read): Linear(in_features=1024, out_features=20, bias=True)
  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (norm_read): BatchNorm1d(20, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
  (drop): Dropout(p=0.1, inplace=False)
)

Total number of trainable parameters is 1793104

**************  Trial 1  **************
Epoch 0: cin|cout=0.001429|0.013771|9.6371
Epoch 1: loss=15.9246|3.0695, acc=4.9779|5.2120, fr=0.6528, cin|cout=0.011751|0.041651|3.5446, lr=0.0150, time=12.610598
-----------------------------

Epoch 2: loss=7.5336|3.0378, acc=4.9902|5.5654, fr=0.3921, cin|cout=0.017894|0.052240|2.9194, lr=0.0150, time=11.237607
-----------------------------

Epoch 3: loss=6.2606|3.0310, acc=5.1373|4.8587, fr=0.3436, cin|cout=0.019694|0.055042|2.7949, lr=0.0150, time=11.325012
-----------------------------

Epoch 4: loss=5.7954|3.0325, acc=5.4071|4.7703, fr=0.3283, cin|cout=0.020200|0.055780|2.7613, lr=0.0150, time=12.372561
-----------------------------

Epoch 5: loss=5.6121|3.0307, acc=5.5787|4.4611, fr=0.3181, cin|cout=0.020396|0.056077|2.7494, lr=0.0150, time=11.946110
-----------------------------

