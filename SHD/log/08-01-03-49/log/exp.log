===== Exp configuration =====
neuron_type:		RLIF
nb_inputs:		700
nb_outputs:		20
nb_layers:		3
nb_hiddens:		256
nb_steps:		100
pdrop:		0.1
normalization:		batchnorm
use_bias:		False
bidirectional:		False
date:		08-01-03-49
use_pretrained_model:		False
only_do_testing:		False
load_exp_folder:		None
new_exp_folder:		./log/08-01-03-49
dataset_name:		shd
data_folder:		./data/raw/
batch_size:		128
nb_epochs:		30
train_input_layer:		True
trial:		5
seed:		-100
dropout:		0
dropout_stop:		0.95
dropout_stepping:		0.0
ckpt_freq:		5
clustering:		False
clustering_factor:		[1, 2.5]
cin_minmax:		[0.001, 0.05]
cout_minmax:		[0.05, 0.2]
nb_cluster:		8
nb_per_cluster:		32
noise_test:		0.0
start_epoch:		0
lr:		0.01
scheduler_patience:		2
scheduler_factor:		0.7
use_regularizers:		False
reg_factor:		0.5
reg_fmin:		0.01
reg_fmax:		0.1
use_augm:		False
use_readout_layer:		True
threshold:		1.0
device:		cuda

Device is set to cuda
checkpoint_dir: ./log/08-01-03-49/checkpoints/

Number of examples in train set: 8156
SHD does not have a validation split. Using test split.
Number of examples in test set: 2264

Created new spiking model:
 SNN(
  (snn): ModuleList(
    (0): RLIFLayer(
      (W): Linear(in_features=700, out_features=256, bias=False)
      (V): Linear(in_features=256, out_features=256, bias=False)
      (norm): BatchNorm1d(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (1): RLIFLayer(
      (W): Linear(in_features=256, out_features=256, bias=False)
      (V): Linear(in_features=256, out_features=256, bias=False)
      (norm): BatchNorm1d(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (2): ReadoutLayer(
      (W): Linear(in_features=256, out_features=20, bias=False)
      (norm): BatchNorm1d(20, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
  )
)

Total number of trainable parameters is 382524

---------------Trial:1---------------


Created new spiking model:
 SNN(
  (snn): ModuleList(
    (0): RLIFLayer(
      (W): Linear(in_features=700, out_features=256, bias=False)
      (V): Linear(in_features=256, out_features=256, bias=False)
      (norm): BatchNorm1d(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (1): RLIFLayer(
      (W): Linear(in_features=256, out_features=256, bias=False)
      (V): Linear(in_features=256, out_features=256, bias=False)
      (norm): BatchNorm1d(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (2): ReadoutLayer(
      (W): Linear(in_features=256, out_features=20, bias=False)
      (norm): BatchNorm1d(20, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
  )
)

Total number of trainable parameters is 382524

------ Begin training ------

Epoch 1: train loss=3.2004, acc=0.0491, fr=0.0047, lr=0.0100, time=29.295979, cin=0.000964, 0.000887, cout=0.025327, 0.033167
Epoch 1: valid loss=3.0152, acc=0.0475, fr=0.0019, mask=0.8750, time=05.565328

Best model saved with valid acc=0.04750631313131313

-----------------------------

Epoch 2: train loss=3.2185, acc=0.0488, fr=0.0047, lr=0.0100, time=26.559230, cin=0.000964, 0.000887, cout=0.025327, 0.033167
Epoch 2: valid loss=3.0598, acc=0.0435, fr=0.0039, mask=0.8750, time=05.542434

-----------------------------

Epoch 3: train loss=3.2148, acc=0.0447, fr=0.0047, lr=0.0100, time=25.882265, cin=0.000964, 0.000887, cout=0.025327, 0.033167
Epoch 3: valid loss=3.1861, acc=0.0392, fr=0.0046, mask=0.8750, time=05.837653

-----------------------------

Epoch 4: train loss=3.2123, acc=0.0428, fr=0.0047, lr=0.0100, time=25.825242, cin=0.000964, 0.000887, cout=0.025327, 0.033167
Epoch 4: valid loss=3.1927, acc=0.0404, fr=0.0046, mask=0.8750, time=05.541076

-----------------------------

Epoch 5: train loss=3.2064, acc=0.0455, fr=0.0047, lr=0.0070, time=26.027956, cin=0.000964, 0.000887, cout=0.025327, 0.033167
Epoch 5: valid loss=3.1993, acc=0.0377, fr=0.0046, mask=0.8750, time=05.276342

-----------------------------

Epoch 6: train loss=3.2093, acc=0.0558, fr=0.0047, lr=0.0070, time=24.482583, cin=0.000964, 0.000887, cout=0.025327, 0.033167
Epoch 6: valid loss=3.2026, acc=0.0384, fr=0.0046, mask=0.8750, time=05.477035

-----------------------------

Epoch 7: train loss=3.2126, acc=0.0491, fr=0.0047, lr=0.0070, time=25.547317, cin=0.000964, 0.000887, cout=0.025327, 0.033167
Epoch 7: valid loss=3.1863, acc=0.0458, fr=0.0046, mask=0.8750, time=05.880468

-----------------------------

