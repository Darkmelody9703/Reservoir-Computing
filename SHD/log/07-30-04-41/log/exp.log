===== Exp configuration =====
neuron_type:		RadLIF
nb_inputs:		700
nb_outputs:		20
nb_layers:		3
nb_hiddens:		1024
nb_steps:		100
pdrop:		0.1
normalization:		batchnorm
use_bias:		False
bidirectional:		False
date:		07-30-04-41
use_pretrained_model:		False
only_do_testing:		False
load_exp_folder:		None
new_exp_folder:		./log/07-30-04-41/
dataset_name:		shd
data_folder:		data/raw/
batch_size:		128
nb_epochs:		50
dropout:		0.0
dropout_stop:		0.95
dropout_stepping:		0.02
ckpt_freq:		5
clustering:		False
clustering_factor:		[0.1, 0.25]
cin_minmax:		[0.001, 0.05]
cout_minmax:		[0.05, 0.2]
noise_test:		0.2
start_epoch:		0
lr:		0.01
scheduler_patience:		2
scheduler_factor:		0.7
use_regularizers:		False
reg_factor:		0.5
reg_fmin:		0.01
reg_fmax:		0.1
use_augm:		False
use_readout_layer:		True
threshold:		1.0
device:		cuda

Device is set to cuda
checkpoint_dir: ./log/07-30-04-41//checkpoints/

Number of examples in train set: 8156
SHD does not have a validation split. Using test split.
Number of examples in test set: 2264

Created new spiking model:
 SNN(
  (snn): ModuleList(
    (0): RadLIFLayer(
      (W): Linear(in_features=700, out_features=1024, bias=False)
      (V): Linear(in_features=1024, out_features=1024, bias=False)
      (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (1): RadLIFLayer(
      (W): Linear(in_features=1024, out_features=1024, bias=False)
      (V): Linear(in_features=1024, out_features=1024, bias=False)
      (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
    (2): ReadoutLayer(
      (W): Linear(in_features=1024, out_features=20, bias=False)
      (norm): BatchNorm1d(20, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
      (drop): Dropout(p=0.1, inplace=False)
    )
  )
)

Total number of trainable parameters is 2129980

------ Begin training ------

Epoch 1: train loss=3.1861, acc=0.0700, fr=0.1155, lr=0.0100, time=0:00:35.399309, cin=0.012284, 0.004212, cout=0.022927, 0.018762
Epoch 1: valid loss=3.7627, acc=0.0731, fr=0.1448, mask=0.8750, time=0:00:05.939511

Best model saved with valid acc=0.07307449494949496

-----------------------------

Epoch 2: train loss=2.4050, acc=0.2253, fr=0.1353, lr=0.0100, time=0:00:29.986542, cin=0.011020, 0.009484, cout=0.022406, 0.007204
Epoch 2: valid loss=2.6554, acc=0.2382, fr=0.1421, mask=0.8785, time=0:00:05.773949

Best model saved with valid acc=0.23824179292929293

-----------------------------

Epoch 3: train loss=1.3966, acc=0.5227, fr=0.1390, lr=0.0100, time=0:00:29.957493, cin=0.008928, 0.010350, cout=0.013703, 0.008147
Epoch 3: valid loss=1.2164, acc=0.5968, fr=0.1459, mask=0.8809, time=0:00:05.810298

Best model saved with valid acc=0.5968276515151515

-----------------------------

Epoch 4: train loss=0.8338, acc=0.7166, fr=0.1435, lr=0.0100, time=0:00:30.505122, cin=0.006954, 0.007283, cout=0.011896, 0.009059
Epoch 4: valid loss=1.1609, acc=0.6628, fr=0.1519, mask=0.8833, time=0:00:05.839851

Best model saved with valid acc=0.6627604166666666

-----------------------------

Epoch 5: train loss=0.6065, acc=0.7937, fr=0.1488, lr=0.0100, time=0:00:29.852361, cin=0.005539, 0.006317, cout=0.019249, 0.013183
Epoch 5: valid loss=0.6028, acc=0.7914, fr=0.1567, mask=0.8856, time=0:00:05.883061

Best model saved with valid acc=0.7914299242424243

-----------------------------

Epoch 6: train loss=0.4645, acc=0.8424, fr=0.1521, lr=0.0100, time=0:00:30.418017, cin=0.004956, 0.006437, cout=0.016950, 0.008266
Epoch 6: valid loss=0.8547, acc=0.7745, fr=0.1580, mask=0.8879, time=0:00:05.877707

-----------------------------

Epoch 7: train loss=0.3781, acc=0.8736, fr=0.1526, lr=0.0100, time=0:00:30.706322, cin=0.004058, 0.007496, cout=0.014289, 0.009476
Epoch 7: valid loss=0.8121, acc=0.7856, fr=0.1600, mask=0.8902, time=0:00:05.912570

-----------------------------

Epoch 8: train loss=0.3216, acc=0.8917, fr=0.1553, lr=0.0100, time=0:00:30.666741, cin=0.004023, 0.006225, cout=0.011362, 0.007753
Epoch 8: valid loss=0.9282, acc=0.7533, fr=0.1621, mask=0.8924, time=0:00:05.886460

-----------------------------

Epoch 9: train loss=0.2496, acc=0.9189, fr=0.1559, lr=0.0070, time=0:00:29.900352, cin=0.003194, 0.005666, cout=0.010084, 0.008141
Epoch 9: valid loss=0.5555, acc=0.8350, fr=0.1617, mask=0.8946, time=0:00:05.794251

Best model saved with valid acc=0.8349510732323232

-----------------------------

Epoch 10: train loss=0.2138, acc=0.9289, fr=0.1561, lr=0.0070, time=0:00:29.792305, cin=0.003510, 0.004919, cout=0.009783, 0.007517
Epoch 10: valid loss=0.6197, acc=0.8178, fr=0.1625, mask=0.8967, time=0:00:05.722570

-----------------------------

Epoch 11: train loss=0.2039, acc=0.9335, fr=0.1566, lr=0.0070, time=0:00:29.467124, cin=0.002833, 0.006073, cout=0.009596, 0.009406
Epoch 11: valid loss=0.7823, acc=0.7951, fr=0.1629, mask=0.8988, time=0:00:05.842874

-----------------------------

Epoch 12: train loss=0.1590, acc=0.9480, fr=0.1572, lr=0.0070, time=0:00:29.120477, cin=0.002360, 0.006125, cout=0.008875, 0.008675
Epoch 12: valid loss=0.7737, acc=0.8084, fr=0.1640, mask=0.9008, time=0:00:05.822138

-----------------------------

Epoch 13: train loss=0.1177, acc=0.9642, fr=0.1582, lr=0.0049, time=0:00:29.522583, cin=0.002029, 0.006345, cout=0.008860, 0.009409
Epoch 13: valid loss=0.6387, acc=0.8414, fr=0.1663, mask=0.9028, time=0:00:05.738296

Best model saved with valid acc=0.8413825757575757

-----------------------------

Epoch 14: train loss=0.1234, acc=0.9585, fr=0.1585, lr=0.0049, time=0:00:29.256074, cin=0.002084, 0.005369, cout=0.009338, 0.008520
Epoch 14: valid loss=0.6523, acc=0.8455, fr=0.1650, mask=0.9048, time=0:00:05.844592

Best model saved with valid acc=0.8454861111111112

-----------------------------

Epoch 15: train loss=0.0948, acc=0.9695, fr=0.1590, lr=0.0049, time=0:00:29.252402, cin=0.002004, 0.004720, cout=0.009117, 0.009986
Epoch 15: valid loss=0.5665, acc=0.8558, fr=0.1662, mask=0.9066, time=0:00:06.007862

Best model saved with valid acc=0.8557844065656566

-----------------------------

Epoch 16: train loss=0.0889, acc=0.9711, fr=0.1599, lr=0.0049, time=0:00:29.519888, cin=0.002077, 0.004683, cout=0.010592, 0.009001
Epoch 16: valid loss=0.5139, acc=0.8713, fr=0.1664, mask=0.9085, time=0:00:05.799725

Best model saved with valid acc=0.8713304924242424

-----------------------------

Epoch 17: train loss=0.0881, acc=0.9704, fr=0.1601, lr=0.0049, time=0:00:29.715417, cin=0.001953, 0.004310, cout=0.010401, 0.009731
Epoch 17: valid loss=0.5871, acc=0.8555, fr=0.1664, mask=0.9104, time=0:00:05.774154

-----------------------------

Epoch 18: train loss=0.0836, acc=0.9727, fr=0.1603, lr=0.0049, time=0:00:29.409206, cin=0.002110, 0.003622, cout=0.010924, 0.009463
Epoch 18: valid loss=0.5604, acc=0.8641, fr=0.1673, mask=0.9122, time=0:00:05.761185

-----------------------------

Epoch 19: train loss=0.0925, acc=0.9668, fr=0.1606, lr=0.0049, time=0:00:29.189091, cin=0.002385, 0.003711, cout=0.008230, 0.009308
Epoch 19: valid loss=0.7954, acc=0.8235, fr=0.1675, mask=0.9139, time=0:00:05.863857

-----------------------------

Epoch 20: train loss=0.0584, acc=0.9804, fr=0.1595, lr=0.0034, time=0:00:29.480002, cin=0.002403, 0.003880, cout=0.007118, 0.009446
Epoch 20: valid loss=0.5417, acc=0.8753, fr=0.1665, mask=0.9156, time=0:00:05.666044

Best model saved with valid acc=0.8753156565656566

-----------------------------

Epoch 21: train loss=0.0492, acc=0.9844, fr=0.1603, lr=0.0034, time=0:00:29.566246, cin=0.002171, 0.003299, cout=0.007268, 0.008352
Epoch 21: valid loss=0.4857, acc=0.8772, fr=0.1671, mask=0.9173, time=0:00:05.658183

Best model saved with valid acc=0.8772490530303031

-----------------------------

Epoch 22: train loss=0.0440, acc=0.9858, fr=0.1600, lr=0.0034, time=0:00:29.334887, cin=0.002222, 0.003290, cout=0.007484, 0.008326
Epoch 22: valid loss=0.6268, acc=0.8554, fr=0.1645, mask=0.9190, time=0:00:05.730198

-----------------------------

Epoch 23: train loss=0.0413, acc=0.9872, fr=0.1594, lr=0.0034, time=0:00:29.403736, cin=0.001807, 0.003136, cout=0.008106, 0.008200
Epoch 23: valid loss=0.5292, acc=0.8742, fr=0.1662, mask=0.9206, time=0:00:05.701290

-----------------------------

Epoch 24: train loss=0.0359, acc=0.9891, fr=0.1596, lr=0.0034, time=0:00:29.859546, cin=0.001688, 0.002990, cout=0.007666, 0.008037
Epoch 24: valid loss=0.5831, acc=0.8697, fr=0.1666, mask=0.9222, time=0:00:05.836291

-----------------------------

Epoch 25: train loss=0.0231, acc=0.9937, fr=0.1602, lr=0.0024, time=0:00:30.905046, cin=0.001651, 0.002842, cout=0.008200, 0.007953
Epoch 25: valid loss=0.4826, acc=0.8887, fr=0.1674, mask=0.9237, time=0:00:06.164378

Best model saved with valid acc=0.8886916035353535

-----------------------------

Epoch 26: train loss=0.0250, acc=0.9921, fr=0.1603, lr=0.0024, time=0:00:29.793972, cin=0.001740, 0.002975, cout=0.007906, 0.008016
Epoch 26: valid loss=0.5768, acc=0.8802, fr=0.1667, mask=0.9252, time=0:00:05.798461

-----------------------------

Epoch 27: train loss=0.0220, acc=0.9924, fr=0.1603, lr=0.0024, time=0:00:29.590462, cin=0.001755, 0.003069, cout=0.007814, 0.008169
Epoch 27: valid loss=0.6206, acc=0.8640, fr=0.1676, mask=0.9267, time=0:00:05.757838

-----------------------------

Epoch 28: train loss=0.0179, acc=0.9953, fr=0.1611, lr=0.0024, time=0:00:29.762399, cin=0.001693, 0.002919, cout=0.007727, 0.007966
Epoch 28: valid loss=0.5411, acc=0.8729, fr=0.1680, mask=0.9282, time=0:00:05.850328

-----------------------------

Epoch 29: train loss=0.0152, acc=0.9962, fr=0.1616, lr=0.0017, time=0:00:30.341249, cin=0.001733, 0.003021, cout=0.007551, 0.008099
Epoch 29: valid loss=0.5503, acc=0.8792, fr=0.1681, mask=0.9296, time=0:00:06.847742

-----------------------------

Epoch 30: train loss=0.0147, acc=0.9960, fr=0.1620, lr=0.0017, time=0:00:32.424627, cin=0.001726, 0.003092, cout=0.007907, 0.008270
Epoch 30: valid loss=0.5310, acc=0.8835, fr=0.1688, mask=0.9310, time=0:00:06.216563

-----------------------------

Epoch 31: train loss=0.0143, acc=0.9962, fr=0.1620, lr=0.0017, time=0:00:31.190276, cin=0.001736, 0.003286, cout=0.007890, 0.008511
Epoch 31: valid loss=0.5672, acc=0.8810, fr=0.1685, mask=0.9323, time=0:00:06.111342

-----------------------------

Epoch 32: train loss=0.0099, acc=0.9983, fr=0.1620, lr=0.0012, time=0:00:33.347704, cin=0.001733, 0.003214, cout=0.007867, 0.008341
Epoch 32: valid loss=0.6150, acc=0.8756, fr=0.1687, mask=0.9336, time=0:00:06.787835

-----------------------------

Epoch 33: train loss=0.0090, acc=0.9978, fr=0.1620, lr=0.0012, time=0:00:32.246283, cin=0.001728, 0.003171, cout=0.008060, 0.008354
Epoch 33: valid loss=0.6179, acc=0.8783, fr=0.1686, mask=0.9349, time=0:00:05.816489

-----------------------------

Epoch 34: train loss=0.0094, acc=0.9983, fr=0.1623, lr=0.0012, time=0:00:30.923433, cin=0.001653, 0.003189, cout=0.007875, 0.008393
Epoch 34: valid loss=0.5595, acc=0.8833, fr=0.1689, mask=0.9362, time=0:00:06.186627

-----------------------------

Epoch 35: train loss=0.0077, acc=0.9983, fr=0.1624, lr=0.0008, time=0:00:29.927861, cin=0.001642, 0.003185, cout=0.007876, 0.008453
Epoch 35: valid loss=0.6542, acc=0.8725, fr=0.1690, mask=0.9375, time=0:00:05.790372

-----------------------------

Epoch 36: train loss=0.0077, acc=0.9979, fr=0.1625, lr=0.0008, time=0:00:30.052249, cin=0.001658, 0.003185, cout=0.007949, 0.008458
Epoch 36: valid loss=0.5566, acc=0.8859, fr=0.1693, mask=0.9387, time=0:00:05.811249

-----------------------------

Epoch 37: train loss=0.0081, acc=0.9977, fr=0.1625, lr=0.0008, time=0:00:29.671445, cin=0.001680, 0.003203, cout=0.008014, 0.008502
Epoch 37: valid loss=0.5953, acc=0.8755, fr=0.1692, mask=0.9400, time=0:00:05.654661

-----------------------------

Epoch 38: train loss=0.0067, acc=0.9984, fr=0.1627, lr=0.0006, time=0:00:29.642894, cin=0.001684, 0.003156, cout=0.008061, 0.008461
Epoch 38: valid loss=0.5442, acc=0.8846, fr=0.1694, mask=0.9412, time=0:00:05.853249

-----------------------------

Epoch 39: train loss=0.0063, acc=0.9987, fr=0.1627, lr=0.0006, time=0:00:29.387901, cin=0.001653, 0.003152, cout=0.008036, 0.008522
Epoch 39: valid loss=0.5035, acc=0.8874, fr=0.1694, mask=0.9423, time=0:00:05.834345

-----------------------------

Epoch 40: train loss=0.0053, acc=0.9990, fr=0.1627, lr=0.0006, time=0:00:30.158239, cin=0.001613, 0.003151, cout=0.008008, 0.008536
Epoch 40: valid loss=0.5487, acc=0.8874, fr=0.1694, mask=0.9435, time=0:00:05.803653

-----------------------------

Epoch 41: train loss=0.0049, acc=0.9991, fr=0.1629, lr=0.0004, time=0:00:31.294183, cin=0.001608, 0.003178, cout=0.007988, 0.008568
Epoch 41: valid loss=0.5689, acc=0.8863, fr=0.1696, mask=0.9446, time=0:00:06.606556

-----------------------------

Epoch 42: train loss=0.0054, acc=0.9989, fr=0.1629, lr=0.0004, time=0:00:30.652934, cin=0.001617, 0.003194, cout=0.007987, 0.008590
Epoch 42: valid loss=0.5522, acc=0.8863, fr=0.1695, mask=0.9457, time=0:00:05.897426

-----------------------------

Epoch 43: train loss=0.0046, acc=0.9991, fr=0.1629, lr=0.0004, time=0:00:30.626979, cin=0.001591, 0.003216, cout=0.007984, 0.008616
Epoch 43: valid loss=0.6083, acc=0.8837, fr=0.1696, mask=0.9468, time=0:00:05.935336

-----------------------------

Epoch 44: train loss=0.0042, acc=0.9993, fr=0.1630, lr=0.0003, time=0:00:33.341152, cin=0.001585, 0.003196, cout=0.008023, 0.008620
Epoch 44: valid loss=0.5467, acc=0.8908, fr=0.1697, mask=0.9479, time=0:00:05.962905

Best model saved with valid acc=0.8908222853535354

-----------------------------

Epoch 45: train loss=0.0053, acc=0.9993, fr=0.1630, lr=0.0003, time=0:00:30.654799, cin=0.001576, 0.003199, cout=0.008072, 0.008644
Epoch 45: valid loss=0.6075, acc=0.8770, fr=0.1696, mask=0.9489, time=0:00:06.058350

-----------------------------

Epoch 46: train loss=0.0046, acc=0.9992, fr=0.1631, lr=0.0003, time=0:00:30.642381, cin=0.001595, 0.003185, cout=0.008059, 0.008666
Epoch 46: valid loss=0.6079, acc=0.8799, fr=0.1698, mask=0.9499, time=0:00:06.115101

-----------------------------

Epoch 47: train loss=0.0045, acc=0.9994, fr=0.1631, lr=0.0003, time=0:00:30.624333, cin=0.001601, 0.003181, cout=0.008037, 0.008720
Epoch 47: valid loss=0.5888, acc=0.8803, fr=0.1697, mask=0.9509, time=0:00:06.058308

-----------------------------

Epoch 48: train loss=0.0039, acc=0.9990, fr=0.1631, lr=0.0002, time=0:00:31.058907, cin=0.001593, 0.003173, cout=0.008050, 0.008726
Epoch 48: valid loss=0.5686, acc=0.8807, fr=0.1698, mask=0.9509, time=0:00:06.276428

-----------------------------

Epoch 49: train loss=0.0051, acc=0.9990, fr=0.1633, lr=0.0002, time=0:00:31.119882, cin=0.001587, 0.003170, cout=0.008028, 0.008722
Epoch 49: valid loss=0.5814, acc=0.8881, fr=0.1700, mask=0.9509, time=0:00:06.072044

-----------------------------

Epoch 50: train loss=0.0034, acc=0.9996, fr=0.1633, lr=0.0002, time=0:00:30.729652, cin=0.001586, 0.003163, cout=0.008051, 0.008709
Epoch 50: valid loss=0.5979, acc=0.8844, fr=0.1700, mask=0.9509, time=0:00:05.980302

-----------------------------


Best valid acc at epoch 44: 0.8908222853535354


------ Training finished ------

Loading best model, epoch=44, valid acc=0.8908222853535354

------ Begin Testing ------

