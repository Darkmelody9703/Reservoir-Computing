{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# from utils import A_cluster\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms, datasets\n",
    "from copy import deepcopy\n",
    "from spikingjelly.datasets.n_mnist import NMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [./data/frames_number_20_split_by_number] already exists.\n",
      "The directory [./data/frames_number_20_split_by_number] already exists.\n"
     ]
    }
   ],
   "source": [
    "nmnist_train = NMNIST('./data/', train=True, data_type='frame', frames_number=20, split_by='number')\n",
    "nmnist_test = NMNIST('./data/', train=False, data_type='frame', frames_number=20, split_by='number')\n",
    "train_loader = torch.utils.data.DataLoader(dataset=nmnist_train, batch_size=256, shuffle=True, drop_last=False, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=nmnist_test, batch_size=256, shuffle=False, drop_last=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 392])\n",
      "torch.Size([256, 392])\n",
      "torch.Size([256, 392])\n",
      "torch.Size([256, 392])\n",
      "torch.Size([256, 392])\n",
      "torch.Size([256, 392])\n",
      "torch.Size([256, 392])\n",
      "torch.Size([256, 392])\n",
      "torch.Size([256, 392])\n",
      "torch.Size([256, 392])\n",
      "torch.Size([256, 392])\n",
      "torch.Size([256, 392])\n",
      "torch.Size([256, 392])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\GitHubClone\\Reservoir-Computing\\NMNIST\\test.ipynb 单元格 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/GitHubClone/Reservoir-Computing/NMNIST/test.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m img, label \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/GitHubClone/Reservoir-Computing/NMNIST/test.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     batch \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/GitHubClone/Reservoir-Computing/NMNIST/test.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(conv1(img[:,\u001b[39m1\u001b[39m]))\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\py\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\py\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\py\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\py\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\py\\lib\\site-packages\\torchvision\\datasets\\folder.py:229\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[39m    index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    228\u001b[0m path, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples[index]\n\u001b[1;32m--> 229\u001b[0m sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloader(path)\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m     sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(sample)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\py\\lib\\site-packages\\spikingjelly\\datasets\\__init__.py:169\u001b[0m, in \u001b[0;36mload_npz_frames\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_npz_frames\u001b[39m(file_name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m    163\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39m    :param file_name: path of the npz file that saves the frames\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[39m    :type file_name: str\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39m    :return: frames\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m    :rtype: np.ndarray\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mload(file_name, allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m'\u001b[39;49m\u001b[39mframes\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\lib\\npyio.py:245\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39mif\u001b[39;00m magic \u001b[39m==\u001b[39m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mMAGIC_PREFIX:\n\u001b[0;32m    244\u001b[0m     \u001b[39mbytes\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzip\u001b[39m.\u001b[39mopen(key)\n\u001b[1;32m--> 245\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(\u001b[39mbytes\u001b[39;49m,\n\u001b[0;32m    246\u001b[0m                              allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mallow_pickle,\n\u001b[0;32m    247\u001b[0m                              pickle_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpickle_kwargs)\n\u001b[0;32m    248\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzip\u001b[39m.\u001b[39mread(key)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\lib\\format.py:777\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    775\u001b[0m             read_count \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(max_read_count, count \u001b[39m-\u001b[39m i)\n\u001b[0;32m    776\u001b[0m             read_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(read_count \u001b[39m*\u001b[39m dtype\u001b[39m.\u001b[39mitemsize)\n\u001b[1;32m--> 777\u001b[0m             data \u001b[39m=\u001b[39m _read_bytes(fp, read_size, \u001b[39m\"\u001b[39;49m\u001b[39marray data\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    778\u001b[0m             array[i:i\u001b[39m+\u001b[39mread_count] \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mfrombuffer(data, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    779\u001b[0m                                                      count\u001b[39m=\u001b[39mread_count)\n\u001b[0;32m    781\u001b[0m \u001b[39mif\u001b[39;00m fortran_order:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\lib\\format.py:906\u001b[0m, in \u001b[0;36m_read_bytes\u001b[1;34m(fp, size, error_template)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    902\u001b[0m     \u001b[39m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[0;32m    903\u001b[0m     \u001b[39m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[0;32m    904\u001b[0m     \u001b[39m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[0;32m    905\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 906\u001b[0m         r \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mread(size \u001b[39m-\u001b[39;49m \u001b[39mlen\u001b[39;49m(data))\n\u001b[0;32m    907\u001b[0m         data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m r\n\u001b[0;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(r) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m==\u001b[39m size:\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\py\\lib\\zipfile.py:925\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    924\u001b[0m \u001b[39mwhile\u001b[39;00m n \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof:\n\u001b[1;32m--> 925\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read1(n)\n\u001b[0;32m    926\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(data):\n\u001b[0;32m    927\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_readbuffer \u001b[39m=\u001b[39m data\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\py\\lib\\zipfile.py:1001\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_type \u001b[39m==\u001b[39m ZIP_DEFLATED:\n\u001b[0;32m   1000\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(n, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMIN_READ_SIZE)\n\u001b[1;32m-> 1001\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decompressor\u001b[39m.\u001b[39;49mdecompress(data, n)\n\u001b[0;32m   1002\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39meof \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m                  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_left \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m                  \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail)\n\u001b[0;32m   1005\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for img, label in train_loader:\n",
    "    batch = img.shape[0]\n",
    "    x = F.relu(conv1(img[:,1]))\n",
    "    x = F.relu(conv2(x))\n",
    "    x = x.view(batch, -1)\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nmnist_train[1][0]\n",
    "x = torch.sign(x.clamp(min=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23950aa4670>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1][x[1]>0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 392])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(2, 8, 3, stride=2)\n",
    "conv2 = nn.Conv2d(8, 8, 3, stride=2)\n",
    "y = conv1(torch.tensor(x[0]).unsqueeze(0))\n",
    "conv2(y).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "首次修改2023年7月13日22:10:55\n",
    "\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# from utils import A_cluster\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms, datasets\n",
    "from copy import deepcopy\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "\n",
    "\n",
    "class config:\n",
    "    input = 700\n",
    "    output = 20\n",
    "    hid = 64         # number of RC Neurons\n",
    "    thr = 0.5\n",
    "    b_j0 = 0.01       # thr baseline\n",
    "    dt = 1\n",
    "    R_m = 1\n",
    "    decay = 0.5\n",
    "    rst = 0.05\n",
    "    lens = 0.5\n",
    "    gamma = 0.5       # gradient scale \n",
    "    gradient_type = 'G' # 'MG', 'slayer', 'linear' 窗型函数\n",
    "    scale = 6.        # special for 'MG'\n",
    "    hight = 0.15      # special for 'MG'\n",
    "\n",
    "    N_hid = hid\n",
    "    p_in = 0.2        # ratio of inhibitory neurons\n",
    "    # gamma = 1.0       # shape factor of gamma distribution\n",
    "    binary = True    # binary matrix of reservoir A\n",
    "    net_type = 'BAC'  # type of reservoir connection topology\n",
    "                      # 'ER',  # Erdos-Renyi Random Network\n",
    "                      # 'ERC', # Clusters of Erdos-Renyi Networks\n",
    "                      # 'BA',  # Barabasi-Albert Network\n",
    "                      # 'BAC', # Clusters of Barabasi-Albert networks\n",
    "                      # 'WS',  # Watts Strogatz small world networks\n",
    "                      # 'WSC', # Clusters of Watts Strogatz small world networks\n",
    "                      # 'RAN', # random network\n",
    "                      # 'DTW', # Developmental Time Window for multi-cluster small-world network\n",
    "    noise = True      # add noise in A\n",
    "    noise_str = 0.05  # noise strength\n",
    "    p_ER = 0.2        # connection probability when creating edges, for ER and WS graphs\n",
    "    m_BA = 3          # number of edges to attach from a new node to existing nodes\n",
    "    k = 5             # number of clusters in A\n",
    "    R = 0.2           # distance factor when deciding connections in random network\n",
    "    scale = False     # rescale matrix A with spectral radius\n",
    "    \n",
    "    input_learn = False # learnable input layer\n",
    "    seed = 123\n",
    "    trials = 5        # try on 5 different seeds\n",
    "    batch = 512\n",
    "    epoch = 100\n",
    "    lr = 0.005\n",
    "    l1 = 0.0003\n",
    "    l1_targ = 2000\n",
    "    fr_norm = 0.01\n",
    "    fr_targ = 0.05\n",
    "    dropout = 0.75\n",
    "    dropout_stepping = 0.015\n",
    "    dropout_stop = 0.95\n",
    "    weight_decay = 1e-4\n",
    "    label_smoothing = False\n",
    "    smoothing = 0.15\n",
    "    norm = False      # add layer norm before each layer\n",
    "    shortcut = False\n",
    "    small_init = True\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "##########################################################\n",
    "########### define surrogate gradient function ###########\n",
    "def gaussian(x, mu=0., sigma=.5):\n",
    "    return torch.exp(-((x - mu) ** 2) / (2 * sigma ** 2)) / torch.sqrt(2 * torch.tensor(torch.pi)) / sigma\n",
    "\n",
    "class ActFun_adp(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):  # input = membrane potential- threshold\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.gt(0).float()  # is firing ???\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):  # approximate the gradients\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        # temp = abs(input) < lens\n",
    "        if config.gradient_type == 'G':\n",
    "            temp = torch.exp(-(input**2)/(2*config.lens**2))/torch.sqrt(2*torch.tensor(torch.pi))/config.lens\n",
    "        elif config.gradient_type == 'MG':\n",
    "            temp = gaussian(input, mu=0., sigma=config.lens) * (1. + config.hight) \\\n",
    "                - gaussian(input, mu=config.lens, sigma=config.scale * config.lens) * config.hight \\\n",
    "                - gaussian(input, mu=-config.lens, sigma=config.scale * config.lens) * config.hight\n",
    "        elif config.gradient_type =='linear':\n",
    "            temp = F.relu(1-input.abs())\n",
    "        elif config.gradient_type == 'slayer':\n",
    "            temp = torch.exp(-5*input.abs())\n",
    "        return grad_input * temp.float() * config.gamma\n",
    "act_fun_adp = ActFun_adp.apply\n",
    "\n",
    "#######################################\n",
    "########### define RC model ###########\n",
    "\n",
    "class RC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RC, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 8, 3, stride=2)\n",
    "        self.conv2 =  nn.Conv2d(8, 8, 3, stride=2)\n",
    "        \n",
    "        self.inpt_hid1 = nn.Linear(392, config.hid)\n",
    "        self.hid1_hid1 = nn.Linear(config.hid, config.hid) # A1\n",
    "        self.hid1_hid2 = nn.Linear(config.hid, config.hid)\n",
    "        self.hid2_hid2 = nn.Linear(config.hid, config.hid) # A2\n",
    "        self.hid2_out = nn.Linear(config.hid, config.output)\n",
    "        if config.small_init:\n",
    "            self.hid1_hid1.weight.data = 0.2 * self.hid1_hid1.weight.data\n",
    "            self.hid2_hid2.weight.data = 0.2 * self.hid2_hid2.weight.data\n",
    "        \n",
    "        nn.init.orthogonal_(self.inpt_hid1.weight)  # 主要用以解决深度网络的梯度消失爆炸问题，在RNN中经常使用\n",
    "        nn.init.orthogonal_(self.hid2_hid2.weight)\n",
    "        nn.init.xavier_uniform_(self.inpt_hid1.weight) # 保持输入输出的方差一致，避免所有输出值都趋向于0。通用方法，适用于任何激活函数\n",
    "        nn.init.xavier_uniform_(self.hid1_hid2.weight)\n",
    "        nn.init.xavier_uniform_(self.hid2_out.weight)\n",
    "        \n",
    "        nn.init.constant_(self.inpt_hid1.bias, 0)\n",
    "        nn.init.constant_(self.hid1_hid2.bias, 0)\n",
    "        nn.init.constant_(self.hid1_hid1.bias, 0)\n",
    "        nn.init.constant_(self.hid2_hid2.bias, 0)\n",
    "        \n",
    "        self.tau_adp_h1 = nn.Parameter(torch.Tensor(config.hid))\n",
    "        self.tau_adp_h2 = nn.Parameter(torch.Tensor(config.hid))\n",
    "        self.tau_adp_o = nn.Parameter(torch.Tensor(config.output))\n",
    "        self.tau_m_h1 = nn.Parameter(torch.Tensor(config.hid))\n",
    "        self.tau_m_h2 = nn.Parameter(torch.Tensor(config.hid))\n",
    "        self.tau_m_o = nn.Parameter(torch.Tensor(config.output))\n",
    "        \n",
    "        nn.init.normal_(self.tau_adp_h1, 150, 10)\n",
    "        nn.init.normal_(self.tau_adp_h2, 150, 10)\n",
    "        nn.init.normal_(self.tau_adp_o, 150, 10)\n",
    "        nn.init.normal_(self.tau_m_h1, 20., 5)\n",
    "        nn.init.normal_(self.tau_m_h2, 20., 5)\n",
    "        nn.init.normal_(self.tau_m_o, 20., 5)\n",
    "        \n",
    "        self.b_hid1 = self.b_hid2 = self.b_o = 0\n",
    "        self.dp = nn.Dropout(0.1)\n",
    "        \n",
    "        if not config.input_learn:\n",
    "            for name, p in self.named_parameters():\n",
    "                if 'conv1' in name or 'conv2' in name:\n",
    "                    p.requires_grad = False\n",
    "    \n",
    "    def output_Neuron(self, inputs, mem, tau_m, dt=1):\n",
    "        \"\"\"The read out neuron is leaky integrator without spike\"\"\"\n",
    "        # alpha = torch.exp(-1. * dt / torch.FloatTensor([30.])).cuda()\n",
    "        alpha = torch.exp(-1. * dt / tau_m).cuda()\n",
    "        mem = mem * alpha + (1. - alpha) * config.R_m * inputs\n",
    "        return mem\n",
    "    \n",
    "    def mem_update_adp(self, inputs, mem, spike, tau_adp, b, tau_m, dt=1, isAdapt=1):\n",
    "        alpha = torch.exp(-1. * dt / tau_m).cuda()\n",
    "        ro = torch.exp(-1. * dt / tau_adp).cuda()\n",
    "        if isAdapt: beta = 1.8\n",
    "        else:       beta = 0.\n",
    "        b = ro * b + (1 - ro) * spike\n",
    "        B = config.b_j0 + beta * b\n",
    "        mem = mem * alpha + (1 - alpha) * config.R_m * inputs - B * spike * dt\n",
    "        spike = act_fun_adp(mem - B)\n",
    "        return mem, spike, B, b\n",
    "    \n",
    "    def forward(self, input, mask):\n",
    "        input = torch.sign(input.clamp(min=0)) # all pixels should be 0 or 1\n",
    "        batch = input.shape[0]\n",
    "        time_step = input.shape[1]\n",
    "        self.b_hid1 = self.b_hid2 = self.b_out = config.b_j0\n",
    "        \n",
    "        hid1_mem = torch.zeros(batch, config.hid).uniform_(0, 0.1).to(config.device)\n",
    "        hid1_spk = torch.zeros(batch, config.hid).to(config.device)\n",
    "        \n",
    "        hid2_mem = torch.zeros(batch, config.hid).uniform_(0, 0.1).to(config.device)\n",
    "        hid2_spk = torch.zeros(batch, config.hid).to(config.device)\n",
    "        \n",
    "        out_mem = torch.zeros(batch, config.output).uniform_(0, 0.1).to(config.device)\n",
    "        output = torch.zeros(batch, config.output).to(config.device)\n",
    "        \n",
    "        sum1_spk = torch.zeros(batch, config.hid).to(config.device)\n",
    "        sum2_spk = torch.zeros(batch, config.hid).to(config.device)\n",
    "        \n",
    "        if config.dropout>0:\n",
    "            self.hid1_hid1.weight.data = self.hid1_hid1.weight.data * mask[0].T.to(config.device)\n",
    "            self.hid2_hid2.weight.data = self.hid2_hid2.weight.data * mask[1].T.to(config.device)\n",
    "        for t in range(time_step):\n",
    "            input_t = input[:,t,:,:,:].float()\n",
    "            ########## Layer 0 ##########\n",
    "            x = F.relu(self.conv1(input_t))\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = x.view(batch, -1)\n",
    "            \n",
    "            \n",
    "            ########## Layer 1 ##########\n",
    "            inpt_hid1 = self.inpt_hid1(x) + self.hid1_hid1(hid1_spk)\n",
    "            hid1_mem, hid1_spk, theta_h1, self.b_h1 = self.mem_update_adp(inpt_hid1, hid1_mem, hid1_spk, self.tau_adp_h1, self.b_hid1,self.tau_m_h1)\n",
    "            sum1_spk += hid1_spk\n",
    "            # hid1_spk = self.dp(hid1_spk)\n",
    "            \n",
    "            ########## Layer 2 ##########\n",
    "            # inpt_hid2 = self.hid1_hid2(hid1_spk) + self.hid2_hid2(hid2_spk)\n",
    "            # hid2_mem, hid2_spk, theta_h2, self.b_h2 = self.mem_update_adp(inpt_hid2, hid2_mem, hid2_spk, self.tau_adp_h2, self.b_hid2,self.tau_m_h2)\n",
    "            # sum2_spk += hid2_spk\n",
    "            # hid2_spk = self.dp(hid2_spk)\n",
    "            \n",
    "            ########## Layer out ########\n",
    "            inpt_out = self.hid2_out(hid1_spk)\n",
    "            out_mem = self.output_Neuron(inpt_out, out_mem, self.tau_m_o)\n",
    "            if t > 5:\n",
    "                output += F.softmax(out_mem, dim=1)\n",
    "            \n",
    "        sum1_spk /= time_step\n",
    "        sum2_spk /= time_step\n",
    "\n",
    "        A_norm = torch.norm(self.hid1_hid1.weight, p=1) + torch.norm(self.hid2_hid2.weight, p=1)\n",
    "        return output, sum1_spk, sum1_spk, A_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RC().to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau_adp_h1 True\n",
      "tau_adp_h2 True\n",
      "tau_adp_o True\n",
      "tau_m_h1 True\n",
      "tau_m_h2 True\n",
      "tau_m_o True\n",
      "conv1.weight False\n",
      "conv1.bias False\n",
      "conv2.weight False\n",
      "conv2.bias False\n",
      "inpt_hid1.weight True\n",
      "inpt_hid1.bias True\n",
      "hid1_hid1.weight True\n",
      "hid1_hid1.bias True\n",
      "hid1_hid2.weight True\n",
      "hid1_hid2.bias True\n",
      "hid2_hid2.weight True\n",
      "hid2_hid2.bias True\n",
      "hid2_out.weight True\n",
      "hid2_out.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    print(name, p.requires_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
